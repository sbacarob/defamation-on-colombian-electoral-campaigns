{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>replies</th>\n",
       "      <th>user</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Los \"pollos\" queremos un Presidente \"pollo\". U...</td>\n",
       "      <td>2018-01-27 22:24:45</td>\n",
       "      <td>629</td>\n",
       "      <td>336</td>\n",
       "      <td>85</td>\n",
       "      <td>708108228568207360</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vota por @IvanDuque en la consulta @CeDemocrat...</td>\n",
       "      <td>2018-01-27 21:51:25</td>\n",
       "      <td>793</td>\n",
       "      <td>535</td>\n",
       "      <td>136</td>\n",
       "      <td>149281495</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compartimos con alegría nuestra propuesta de p...</td>\n",
       "      <td>2018-01-27 21:50:15</td>\n",
       "      <td>188</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>77653794</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.@FNAraujoR  #4 Senado @IvanDuque #ElCandidato...</td>\n",
       "      <td>2018-01-27 21:46:13</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1069678676</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The girls flocking to see Mr. Duque.  That's g...</td>\n",
       "      <td>2018-01-27 20:54:10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>876674787115925504</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                 date  \\\n",
       "0  Los \"pollos\" queremos un Presidente \"pollo\". U...  2018-01-27 22:24:45   \n",
       "1  Vota por @IvanDuque en la consulta @CeDemocrat...  2018-01-27 21:51:25   \n",
       "2  Compartimos con alegría nuestra propuesta de p...  2018-01-27 21:50:15   \n",
       "3  .@FNAraujoR  #4 Senado @IvanDuque #ElCandidato...  2018-01-27 21:46:13   \n",
       "4  The girls flocking to see Mr. Duque.  That's g...  2018-01-27 20:54:10   \n",
       "\n",
       "   favorited  retweeted  replies                user lang  \n",
       "0        629        336       85  708108228568207360   es  \n",
       "1        793        535      136           149281495   es  \n",
       "2        188        119        4            77653794   es  \n",
       "3         34         27        2          1069678676   es  \n",
       "4          1          0        0  876674787115925504   en  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We import the data\n",
    "df = pd.read_csv('data/processed_data.csv', usecols=['text', 'date', 'favorited', 'retweeted', 'replies', 'user', 'lang'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>replies</th>\n",
       "      <th>user</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-27 22:24:45</th>\n",
       "      <td>Los \"pollos\" queremos un Presidente \"pollo\". U...</td>\n",
       "      <td>629</td>\n",
       "      <td>336</td>\n",
       "      <td>85</td>\n",
       "      <td>708108228568207360</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-27 21:51:25</th>\n",
       "      <td>Vota por @IvanDuque en la consulta @CeDemocrat...</td>\n",
       "      <td>793</td>\n",
       "      <td>535</td>\n",
       "      <td>136</td>\n",
       "      <td>149281495</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-27 21:50:15</th>\n",
       "      <td>Compartimos con alegría nuestra propuesta de p...</td>\n",
       "      <td>188</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>77653794</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-27 21:46:13</th>\n",
       "      <td>.@FNAraujoR  #4 Senado @IvanDuque #ElCandidato...</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1069678676</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-27 20:54:10</th>\n",
       "      <td>The girls flocking to see Mr. Duque.  That's g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>876674787115925504</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2018-01-27 22:24:45  Los \"pollos\" queremos un Presidente \"pollo\". U...   \n",
       "2018-01-27 21:51:25  Vota por @IvanDuque en la consulta @CeDemocrat...   \n",
       "2018-01-27 21:50:15  Compartimos con alegría nuestra propuesta de p...   \n",
       "2018-01-27 21:46:13  .@FNAraujoR  #4 Senado @IvanDuque #ElCandidato...   \n",
       "2018-01-27 20:54:10  The girls flocking to see Mr. Duque.  That's g...   \n",
       "\n",
       "                     favorited  retweeted  replies                user lang  \n",
       "date                                                                         \n",
       "2018-01-27 22:24:45        629        336       85  708108228568207360   es  \n",
       "2018-01-27 21:51:25        793        535      136           149281495   es  \n",
       "2018-01-27 21:50:15        188        119        4            77653794   es  \n",
       "2018-01-27 21:46:13         34         27        2          1069678676   es  \n",
       "2018-01-27 20:54:10          1          0        0  876674787115925504   en  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, we convert the date column into dates\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# And set it as the index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding columns to identify the mentioned candidates\n",
    "\n",
    "As with the analyzing the data notebook, we'll add a couple of columns to indicate which of the candidates are mentioned on each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>replies</th>\n",
       "      <th>user</th>\n",
       "      <th>lang</th>\n",
       "      <th>mentions_duque</th>\n",
       "      <th>mentions_petro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-27 22:24:45</th>\n",
       "      <td>Los \"pollos\" queremos un Presidente \"pollo\". U...</td>\n",
       "      <td>629</td>\n",
       "      <td>336</td>\n",
       "      <td>85</td>\n",
       "      <td>708108228568207360</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-27 21:51:25</th>\n",
       "      <td>Vota por @IvanDuque en la consulta @CeDemocrat...</td>\n",
       "      <td>793</td>\n",
       "      <td>535</td>\n",
       "      <td>136</td>\n",
       "      <td>149281495</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-27 21:50:15</th>\n",
       "      <td>Compartimos con alegría nuestra propuesta de p...</td>\n",
       "      <td>188</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>77653794</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-27 21:46:13</th>\n",
       "      <td>.@FNAraujoR  #4 Senado @IvanDuque #ElCandidato...</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1069678676</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-27 20:54:10</th>\n",
       "      <td>The girls flocking to see Mr. Duque.  That's g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>876674787115925504</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2018-01-27 22:24:45  Los \"pollos\" queremos un Presidente \"pollo\". U...   \n",
       "2018-01-27 21:51:25  Vota por @IvanDuque en la consulta @CeDemocrat...   \n",
       "2018-01-27 21:50:15  Compartimos con alegría nuestra propuesta de p...   \n",
       "2018-01-27 21:46:13  .@FNAraujoR  #4 Senado @IvanDuque #ElCandidato...   \n",
       "2018-01-27 20:54:10  The girls flocking to see Mr. Duque.  That's g...   \n",
       "\n",
       "                     favorited  retweeted  replies                user lang  \\\n",
       "date                                                                          \n",
       "2018-01-27 22:24:45        629        336       85  708108228568207360   es   \n",
       "2018-01-27 21:51:25        793        535      136           149281495   es   \n",
       "2018-01-27 21:50:15        188        119        4            77653794   es   \n",
       "2018-01-27 21:46:13         34         27        2          1069678676   es   \n",
       "2018-01-27 20:54:10          1          0        0  876674787115925504   en   \n",
       "\n",
       "                     mentions_duque  mentions_petro  \n",
       "date                                                 \n",
       "2018-01-27 22:24:45            True           False  \n",
       "2018-01-27 21:51:25            True           False  \n",
       "2018-01-27 21:50:15           False           False  \n",
       "2018-01-27 21:46:13            True           False  \n",
       "2018-01-27 20:54:10           False           False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mentions_duque'] = df['text'].str.lower().str.contains('@ivanduque')\n",
    "df['mentions_petro'] = df['text'].str.lower().str.contains('@petrogustavo')\n",
    "\n",
    "# Let's set those columns as boolean\n",
    "df['mentions_duque'] = df['mentions_duque'].astype('bool')\n",
    "df['mentions_petro'] = df['mentions_petro'].astype('bool')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing tweets created by the candidates\n",
    "\n",
    "Now, as in the previous notebook, we will remove the tweets created by the candidates themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df['user'] == 77653794) | (df['user'] == 49849732)].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a part-of-speech (POS) tagger\n",
    "\n",
    "Now, in order to see if some POS tags are more frequent than others in general or if it varies from one candidate to the other, we'll create a POS tagger and apply it over the corpus of our text.\n",
    "\n",
    "for this section you'll need NLKT, and the cess_esp corpus downloaded.\n",
    "\n",
    "You can download it by running (from a Python console or script):\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('cess_esp')\n",
    "```\n",
    "\n",
    "Victor Peinado provided a mapping from the whole spanish tagset to the universal tagset. I think it's part of the AnCora corpus, and you can download it from [here](https://github.com/vitojph/kschool-nlp-13/blob/master/data/es-ancora.map)\n",
    "\n",
    "After downloading it, you should place it in the `universal_tagset` folder of NLTK like this:\n",
    "\n",
    "```bash\n",
    "$ cd /path/to/your/downloaded/file\n",
    "$ cp es-ancora.map ~/nltk_data/taggers/universal_tagset\n",
    "```\n",
    "\n",
    "And with all that, you should be good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('El', 'DET'), ('grupo', 'NOUN'), ('estatal', 'ADJ'), ('Electricité_de_France', 'NOUN'), ('-Fpa-', '.'), ('EDF', 'NOUN'), ('-Fpt-', '.'), ('anunció', 'VERB'), ('hoy', 'ADV'), (',', '.'), ('jueves', 'X'), (',', '.'), ('la', 'DET'), ('compra', 'NOUN'), ('del', 'ADP'), ('51_por_ciento', 'NUM'), ('de', 'ADP'), ('la', 'DET'), ('empresa', 'NOUN'), ('mexicana', 'ADJ'), ('Electricidad_Águila_de_Altamira', 'NOUN'), ('-Fpa-', '.'), ('EAA', 'NOUN'), ('-Fpt-', '.'), (',', '.'), ('creada', 'ADJ'), ('por', 'ADP'), ('el', 'DET'), ('japonés', 'ADJ'), ('Mitsubishi_Corporation', 'NOUN'), ('para', 'ADP'), ('poner_en_marcha', 'VERB'), ('una', 'DET'), ('central', 'NOUN'), ('de', 'ADP'), ('gas', 'NOUN'), ('de', 'ADP'), ('495', 'X'), ('megavatios', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# We import NLTK and the cess_esp corpus\n",
    "import nltk\n",
    "from nltk.corpus import cess_esp\n",
    "\n",
    "# We specify that the corpus should use the 'es-ancora' tagset\n",
    "cess_esp._tagset = 'es-ancora'\n",
    "\n",
    "# We get the tagged sentences from the corpus\n",
    "tagged_sents = cess_esp.tagged_sents(tagset='universal')\n",
    "\n",
    "# Let's look what one of those looks like\n",
    "print(tagged_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we define a size for the train set\n",
    "size = int(len(tagged_sents) * 0.9)\n",
    "\n",
    "# And split the corpus into train and test sets using the defined size\n",
    "train, test = tagged_sents[:size], tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive solution\n",
    "\n",
    "For our first naive solution we'll create a default tagger, to classify everything as a noun.\n",
    "\n",
    "We'll then create a unigram tagger trained on the train set, and use the default tagger as a backoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the default tagger, to tag everything as a noun\n",
    "default_tagger = nltk.DefaultTagger('NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a unigram tagger, trained with the train set, and using the default_tagger as a backoff\n",
    "unigram_tagger = nltk.UnigramTagger(train, backoff=default_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at how this tagger performs against the test set and against our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8808672009158558"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well this isn't bad at all.\n",
    "\n",
    "Let's try it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[('Vota', 'NOUN'), ('por', 'ADP'), ('@IvanDuque', 'NOUN'), ('en', 'ADP'), ('la', 'DET'), ('consulta', 'NOUN'), ('@CeDemocratico', 'NOUN'), ('el', 'DET'), ('partido', 'NOUN'), ('del', 'ADP'), ('Uribismo', 'NOUN'), ('y', 'CONJ'), ('de', 'ADP'), ('@AlvaroUribeVel', 'NOUN'), ('pic.twitter.com/7CzVECAOHu', 'NOUN')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[('.@FNAraujoR', 'NOUN'), ('#4', 'NOUN'), ('Senado', 'NOUN'), ('@IvanDuque', 'NOUN'), ('#ElCandidatoDeLaEsperanza', 'NOUN'), ('#1', 'NOUN'), ('en', 'ADP'), ('la', 'DET'), ('Consulta', 'NOUN'), ('Interpartidista', 'NOUN'), ('@AlvaroUribeVel', 'NOUN'), ('#', 'NOUN'), ('1', 'X'), ('Senado', 'NOUN'), ('.@CeDemocratico', 'NOUN'), (',', '.'), ('están', 'VERB'), ('sembrando', 'NOUN'), ('Esperanza', 'NOUN'), ('en', 'ADP'), ('cada', 'DET'), ('Rincón', 'NOUN'), ('de', 'ADP'), ('La', 'DET'), ('Patria', 'NOUN'), ('para', 'ADP'), ('que', 'PRON'), ('los', 'DET'), ('tiempos', 'NOUN'), ('de', 'ADP'), ('la', 'DET'), ('Seguridad', 'NOUN'), ('Democrática', 'NOUN'), ('Regrese.', 'NOUN'), ('#LoMejorEstaPorVenir', 'NOUN'), ('pic.twitter.com/RWrmqrwYfm', 'NOUN')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[('The', 'NOUN'), ('girls', 'NOUN'), ('flocking', 'NOUN'), ('to', 'NOUN'), ('see', 'NOUN'), ('Mr.', 'NOUN'), ('Duque.', 'NOUN'), (\"That's\", 'NOUN'), ('good.', 'NOUN')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[('#FelizSábado,', 'NOUN'), ('hoy', 'ADV'), ('durante', 'ADP'), ('reunión', 'NOUN'), ('en', 'ADP'), ('Medellín', 'NOUN'), ('el', 'DET'), ('expresidente', 'NOUN'), ('@AlvaroUribeVel', 'NOUN'), ('y', 'CONJ'), ('el', 'DET'), ('Candidato', 'NOUN'), ('@IvanDuque', 'NOUN'), ('reiteraron', 'VERB'), ('nuestro', 'DET'), ('compromiso', 'NOUN'), ('por', 'ADP'), ('recuperar', 'VERB'), ('la', 'DET'), ('seguridad', 'NOUN'), ('del', 'ADP'), ('país.', 'NOUN'), ('pic.twitter.com/yed48GqJ0B', 'NOUN')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in df['text'][1:5]:\n",
    "    print(\"\\n\")\n",
    "    print(unigram_tagger.tag(text.split()))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not bad at all. But let's try to create a slightly better tagger.\n",
    "\n",
    "### Creating a slightly better tagger\n",
    "\n",
    "We'll repeat the same we did with the unigram tagger and the default tagger.\n",
    "\n",
    "For this, we'll create a bigram tagger, which will use the unigram tagge as a backoff, and a trigram tagger, which will use the bigram tagger as a backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a bigram tagger, trained with the train set, and using the unigram_tagger as a backoff\n",
    "bigram_tagger = nltk.BigramTagger(train, backoff=unigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a trigram tagger, trained with the train set and using the bigram_tagger as a backoff\n",
    "trigram_tagger = nltk.TrigramTagger(train, backoff=bigram_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see how it compares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8943188322839153"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And let's see what the precision of this final tagger is\n",
    "trigram_tagger.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the improvement from the previous tagger isn't that much, but it's now nearly at 90%\n",
    "\n",
    "Now let's see if we might spot any difference with our tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[('Vota', 'NOUN'), ('por', 'ADP'), ('@IvanDuque', 'NOUN'), ('en', 'ADP'), ('la', 'DET'), ('consulta', 'NOUN'), ('@CeDemocratico', 'NOUN'), ('el', 'DET'), ('partido', 'NOUN'), ('del', 'ADP'), ('Uribismo', 'NOUN'), ('y', 'CONJ'), ('de', 'ADP'), ('@AlvaroUribeVel', 'NOUN'), ('pic.twitter.com/7CzVECAOHu', 'NOUN')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[('.@FNAraujoR', 'NOUN'), ('#4', 'NOUN'), ('Senado', 'NOUN'), ('@IvanDuque', 'NOUN'), ('#ElCandidatoDeLaEsperanza', 'NOUN'), ('#1', 'NOUN'), ('en', 'ADP'), ('la', 'DET'), ('Consulta', 'NOUN'), ('Interpartidista', 'NOUN'), ('@AlvaroUribeVel', 'NOUN'), ('#', 'NOUN'), ('1', 'X'), ('Senado', 'NOUN'), ('.@CeDemocratico', 'NOUN'), (',', '.'), ('están', 'VERB'), ('sembrando', 'NOUN'), ('Esperanza', 'NOUN'), ('en', 'ADP'), ('cada', 'DET'), ('Rincón', 'NOUN'), ('de', 'ADP'), ('La', 'DET'), ('Patria', 'NOUN'), ('para', 'ADP'), ('que', 'CONJ'), ('los', 'DET'), ('tiempos', 'NOUN'), ('de', 'ADP'), ('la', 'DET'), ('Seguridad', 'NOUN'), ('Democrática', 'NOUN'), ('Regrese.', 'NOUN'), ('#LoMejorEstaPorVenir', 'NOUN'), ('pic.twitter.com/RWrmqrwYfm', 'NOUN')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[('The', 'NOUN'), ('girls', 'NOUN'), ('flocking', 'NOUN'), ('to', 'NOUN'), ('see', 'NOUN'), ('Mr.', 'NOUN'), ('Duque.', 'NOUN'), (\"That's\", 'NOUN'), ('good.', 'NOUN')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[('#FelizSábado,', 'NOUN'), ('hoy', 'ADV'), ('durante', 'ADP'), ('reunión', 'NOUN'), ('en', 'ADP'), ('Medellín', 'NOUN'), ('el', 'DET'), ('expresidente', 'NOUN'), ('@AlvaroUribeVel', 'NOUN'), ('y', 'CONJ'), ('el', 'DET'), ('Candidato', 'NOUN'), ('@IvanDuque', 'NOUN'), ('reiteraron', 'VERB'), ('nuestro', 'DET'), ('compromiso', 'NOUN'), ('por', 'ADP'), ('recuperar', 'VERB'), ('la', 'DET'), ('seguridad', 'NOUN'), ('del', 'ADP'), ('país.', 'NOUN'), ('pic.twitter.com/yed48GqJ0B', 'NOUN')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in df['text'][1:5]:\n",
    "    print(\"\\n\")\n",
    "    print(trigram_tagger.tag(text.split()))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the top it's not easy to spot a difference. But let's run a little snippet to see if there are any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items at position [1,26] differ.\n",
      "Unigram tagger produced: ('que', 'PRON')\n",
      "Trigram tagger produced: ('que', 'CONJ')\n"
     ]
    }
   ],
   "source": [
    "l1 = [unigram_tagger.tag(text.split()) for text in df['text'][1:5]]\n",
    "l2 = [trigram_tagger.tag(text.split()) for text in df['text'][1:5]]\n",
    "\n",
    "for i in range(0, len(l1)):\n",
    "    for j in range(0, len(l1[i])):\n",
    "        if l1[i][j] != l2[i][j]:\n",
    "            print(\"Items at position [{},{}] differ.\\nUnigram tagger produced: {}\\nTrigram tagger produced: {}\".format(i, j, l1[i][j], l2[i][j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the results show that only one word from all of the first five sentences was classified differently.\n",
    "\n",
    "The word was 'que'. The unigram tagger tagged it as a pronoun. Whereas the trigram tagger tagged it as a conjunction.\n",
    "\n",
    "This makes a lot of sense, since unigram taggers only tag words per se, that is, completely ignoring the context. While a trigram tagger takes into account the neighbouring words, allowing for examples like this to be classified correctly.\n",
    "\n",
    "And to be fair, one word in five sentences isn't irrelevant.\n",
    "\n",
    "Now, another thing that comes to attention is the fact that the fourth tweet was actually in english. And therefore, all of the words in that tweet classified as nouns.\n",
    "\n",
    "So, we can fix this taking advantage of NLTK's tools.\n",
    "\n",
    "### Using a different tagger for english\n",
    "\n",
    "We'll create some english taggers and use those to tag the tweets that Twitter identified to be in english, and we'll keep using our trigram_tagger for the rest of the tweets.\n",
    "\n",
    "For this, we'll use the example taggers created by Victor Peinado on his class notebooks. You can find that [here](https://github.com/vitojph/kschool-nlp-13/blob/8cc2b8c5815d41b51ee2e2bc4789dd7ef4779646/notebooks/pos-tagger-es.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first thing is to include the brown corpus, to use it to train the classifiers.\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# And we store the tagged sents from articles in the news category. We use the universal tagset here as well.\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news', tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we use the same Regular expressions used by Victor Peinado and create a regex tagger, just like he does\n",
    "\n",
    "patterns = [\n",
    "    (r'[Aa]m$', 'BEM'),               # irregular forms of 'to be' \n",
    "    (r'[Aa]re$', 'BER'),              #  \n",
    "    (r'[Ii]s$', 'BEZ'),               #  \n",
    "    (r'[Ww]as$', 'BEDZ'),             #  \n",
    "    (r'[Ww]ere$', 'BED'),             #  \n",
    "    (r'[Bb]een$', 'BEN'),             #  \n",
    "    (r'[Hh]ave$', 'HV'),              # irregular forms of 'to be' \n",
    "    (r'[Hh]as$', 'HVZ'),              #  \n",
    "    (r'[Hh]ad$', 'HVD'),              #\n",
    "    (r'I$', 'PRP'),                   # personal pronouns\n",
    "    (r'[Yy]ou$', 'PRP'),              # \n",
    "    (r'[Hh]e$', 'PRP'),               # \n",
    "    (r'[Ss]he$', 'PRP'),              # \n",
    "    (r'[Ii]t$', 'PRP'),               # \n",
    "    (r'[Tt]hey$', 'PRP'),             # \n",
    "    (r'[Aa]n?$', 'AT'),               # \n",
    "    (r'[Tt]he$', 'AT'),               # \n",
    "    (r'[Ww]h.+$', 'WP'),              # wh- pronoun\n",
    "    (r'.*ing$', 'VBG'),               # gerunds\n",
    "    (r'.*ed$', 'VBD'),                # simple past\n",
    "    (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "    (r'[Cc]an(not|n\\'t)?$', 'MD'),    # modals\n",
    "    (r'[Mm]ight$', 'MD'),             # \n",
    "    (r'[Mm]ay$', 'MD'),               # \n",
    "    (r'.+ould$', 'MD'),               # modals: could, should, would\n",
    "    (r'.*ly$', 'RB'),                 # adverbs\n",
    "    (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                 # plural nouns\n",
    "    (r'-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n",
    "    (r'^to$', 'TO'),                  # to \n",
    "    (r'^in$', 'IN'),                  # in prep\n",
    "    (r'^[A-Z]+([a-z])*$', 'NNP'),     # proper nouns \n",
    "    (r'.*', 'NN')                     # nouns (default)\n",
    "]\n",
    "\n",
    "regex_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we define a size for train and test sets, just like with the spanish tagger\n",
    "brown_size = int(len(brown_tagged_sents) * 0.9)\n",
    "brown_train, brown_test = brown_tagged_sents[:brown_size], brown_tagged_sents[brown_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally we create the ngram taggers with backoff on the previous one\n",
    "# and for unigrams tagger with the regex tagger for a backoff\n",
    "en_unigram_tagger = nltk.UnigramTagger(brown_train, backoff=regex_tagger)\n",
    "\n",
    "en_bigram_tagger = nltk.BigramTagger(brown_train, backoff=en_unigram_tagger)\n",
    "\n",
    "en_trigram_tagger = nltk.TrigramTagger(brown_train, backoff=en_bigram_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's look at the result of tagging that tweet that was in english with the new `en_trigram_tagger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('girls', 'NOUN'),\n",
       " ('flocking', 'VBG'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Duque.', 'NN'),\n",
       " (\"That's\", 'PRT'),\n",
       " ('good.', 'NN')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_trigram_tagger.tag(df['text'][3].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. This is all that we need.\n",
    "\n",
    "Now let's actually tag the text of all of our tweets.\n",
    "\n",
    "## Tagging the text of all of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's bring in our handy remove_special_characters function from the previous notebook.\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    period = re.compile(\"(\\.|\\:)\")\n",
    "    # We remove periods only if they're at the first or last position\n",
    "    if period.match(text, 0, 1):\n",
    "        text = text[1:]\n",
    "    if period.match(text, len(text) - 1, len(text)):\n",
    "        text = text[:-1]\n",
    "    # And we remove special characters other than periods, hash signs, ad signs, letters with tildes, and numbers\n",
    "    text = re.sub(\"[^\\:a-zA-Z0-9áéíóúüñÁÉÍÓÚÑ\\.#@\\/\\s]\", \"\", text)\n",
    "    # Finally, we return the lowercase version of the word\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a little extra step, we need to remove words with no tweet text\n",
    "df = df[~df['text'].isnull()]\n",
    "\n",
    "# Now, we create an array to store all of the words with their respective tag\n",
    "duque_tagged_words = []\n",
    "petro_tagged_words = []\n",
    "other_tagged_words = []\n",
    "\n",
    "# And we iterate over the dataframe, populating the list\n",
    "for (_, x) in df.iterrows():\n",
    "    tweet_words = list(map(remove_special_characters, x['text'].split()))\n",
    "    if x['lang'] == 'en':\n",
    "        # We use the english tagger if the detected language is english\n",
    "        tagged_words = en_trigram_tagger.tag(tweet_words)\n",
    "    else:\n",
    "        # Otherwise, we use the spanish tagger\n",
    "        tagged_words = trigram_tagger.tag(tweet_words)\n",
    "    if x['mentions_duque'] and not x['mentions_petro']:\n",
    "        duque_tagged_words += tagged_words\n",
    "    elif x['mentions_petro'] and not x['mentions_duque']:\n",
    "        petro_tagged_words += tagged_words\n",
    "    else:\n",
    "        other_tagged_words += tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230650 283820 161637\n"
     ]
    }
   ],
   "source": [
    "print(len(duque_tagged_words), len(petro_tagged_words), len(other_tagged_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got all of the words tagged and classified by the candidate they mention.\n",
    "\n",
    "Let's now calculate the frequency for the tags of the tweets mentioning the different candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create empty dicts to store the frequencies\n",
    "duque_tags_freq = {}\n",
    "petro_tags_freq = {}\n",
    "other_tags_freq = {}\n",
    "\n",
    "# And we populate them like we did in the other notebook with the different ngrams\n",
    "for (_word, tag) in duque_tagged_words:\n",
    "    duque_tags_freq[tag] = duque_tags_freq.get(tag, 0) + 1\n",
    "\n",
    "for (_word, tag) in petro_tagged_words:\n",
    "    petro_tags_freq[tag] = petro_tags_freq.get(tag, 0) + 1\n",
    "\n",
    "for (_word, tag) in other_tagged_words:\n",
    "    other_tags_freq[tag] = other_tags_freq.get(tag, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally let's sort them by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tags = {\n",
    "    'petro': sorted(petro_tags_freq.items(), key=lambda kv: kv[1], reverse=True),\n",
    "    'duque': sorted(duque_tags_freq.items(), key=lambda kv: kv[1], reverse=True),\n",
    "    'other': sorted(other_tags_freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the most frequent tags by candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypos = np.arange(20)\n",
    "\n",
    "fig, (ax, ax2) = plt.subplots(ncols=2, figsize=(15, 6))\n",
    "\n",
    "petro_data = dict(sorted_tags['petro'])\n",
    "duque_data = dict(sorted_tags['duque'])\n",
    "\n",
    "ax.barh(ypos, list(petro_data.values()), align='center')\n",
    "ax.set_yticks(ypos)\n",
    "ax.set_yticklabels(list(petro_data.keys()))\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_title(\"Most frequent tags on tweets mentioning Petro\")\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax2.barh(ypos, list(duque_data.values()), align='center')\n",
    "ax2.set_yticks(ypos)\n",
    "ax2.set_yticklabels(list(duque_data.keys()))\n",
    "ax2.set_xlabel('Frequency')\n",
    "ax2.set_title(\"Most frequent tags on tweets mentioning Duque\")\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've got the results.\n",
    "\n",
    "They don't really seem very interesting.\n",
    "\n",
    "The most frequent tag in both cases was NOUN. This makes complete sense, because all of the hashtags and twitter handles are being tagged as nouns. Also, all of the words that cannot be correctly tagged, are tagged as NOUNs.\n",
    "\n",
    "Then come the ADP and DET tags. Which makes a lot of sense, because most of the stopwords fall into these tags, and as was seen on the previous notebook, stopwords have the highest frequencies in text.\n",
    "\n",
    "The only difference that's probably worth mentioning, is that the tweets mentioning Ivan Duque contained more adjectives than those mentioning Gustavo Petro. This could be because of his followers flattering him, or because of his oppositors insulting him.\n",
    "\n",
    "# Analyzing sentiment\n",
    "\n",
    "Sentiment analysis is a challenge by itself. But libraries such as TextBlob make it easier. However, these libraries make it easier for identifying sentiment on english sentences. It's not as easy with spanish. So, we'll create a sentiment analyzer that works with text in spanish.\n",
    "\n",
    "## TASS corpus\n",
    "\n",
    "Luckily for us, TASS, the Taller de Análisis Semántico de la SEPLN (Sociedad Española para el Procesamiento de Lenguaje Natural), makes their tagged datasets available for non commercial use. You can fill out a form to obtain a license and receive links to download TASS datasets [here](http://www.sepln.org/workshops/tass/tass_data/download.php)\n",
    "\n",
    "TASS holds yearly challenges regarding sentiment analysis classification.\n",
    "\n",
    "The task #1 for the 2018 challenge was sentiment analysis of tweet data. You can read all about it [here](http://www.sepln.org/workshops/tass/2018/task-1/). So, this dataset is perfect for this project!\n",
    "\n",
    "So, let's get to it.\n",
    "\n",
    "I've downloaded it and added it to the `/data` directory. If you want to replicate this you'll have to apply for a license and download the data, for I'm not allowed to distribute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general-test.xml\r\n",
      "general-train-tagged.xml\r\n",
      "intertass-CR-development-tagged.xml\r\n",
      "intertass-CR-test.xml\r\n",
      "intertass-CR-train-tagged.xml\r\n",
      "intertass-ES-development-tagged.xml\r\n",
      "intertass-ES-test.xml\r\n",
      "intertass-ES-train-tagged.xml\r\n",
      "intertass-PE-development-tagged.xml\r\n",
      "intertass-PE-test.xml\r\n",
      "intertass-PE-train-tagged.xml\r\n"
     ]
    }
   ],
   "source": [
    "# Let's see the files we've downloaded from TASS\n",
    "! ls data/ | grep xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, these are all the datasets we have.\n",
    "\n",
    "The ones containing **'CR'** are from Costa Rican tweets. The ones containing **'PE'** are from Peruvian tweets. And the ones containing **'ES'** are from Spanish tweets.\n",
    "\n",
    "The other two that remain are general datasets.\n",
    "\n",
    "As you may see, all of these files come in xml format, so we'll need to parse them in order to be able to use them\n",
    "\n",
    "### Parsing XML files\n",
    "\n",
    "Let's first take a look at what the structure of this XML files looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n",
      "<tweets>\r\n",
      "\t<tweet>\r\n",
      "\t\t<tweetid>770976639173951488</tweetid>\r\n",
      "\t\t<user>noseashetero</user>\r\n",
      "\t\t<content>@noseashetero 1000/10 de verdad a ti que voy a decir petarda que te quiero más que a mí mismo  ✨</content>\r\n",
      "\t\t<date>2016-08-31 13:28:49</date>\r\n",
      "\t\t<lang>es</lang>\r\n",
      "\t\t<sentiment>\r\n",
      "\t\t\t<polarity><value>P</value></polarity>\r\n",
      "\t\t</sentiment>\r\n",
      "\t</tweet>\r\n",
      "\t<tweet>\r\n",
      "\t\t<tweetid>771092421866389508</tweetid>\r\n",
      "\t\t<user>Templelx</user>\r\n",
      "\t\t<content>@piscolabisaereo @HistoriaNG @SPosteguillo las tengo pero aún no las he leído. Caerán prontito </content>\r\n",
      "\t\t<date>2016-08-31 21:08:54</date>\r\n",
      "\t\t<lang>es</lang>\r\n",
      "\t\t<sentiment>\r\n",
      "\t\t\t<polarity><value>P</value></polarity>\r\n",
      "\t\t</sentiment>\r\n",
      "\t</tweet>\r\n",
      "\t<tweet>\r\n",
      "\t\t<tweetid>771092111429083136</tweetid>\r\n",
      "\t\t<user>esskuu94</user>\r\n",
      "\t\t<content>Al final han sido 3h  Bueno, mañana tengo fiesta así que.. No me quejo </content>\r\n",
      "\t\t<date>2016-08-31 21:07:40</date>\r\n",
      "\t\t<lang>es</lang>\r\n",
      "\t\t<sentiment>\r\n",
      "\t\t\t<polarity><value>P</value></polarity>\r\n",
      "\t\t</sentiment>\r\n",
      "\t</tweet>\r\n",
      "\t<tweet>\r\n",
      "\t\t<tweetid>771092070572449796</tweetid>\r\n",
      "\t\t<user>__ariadna9</user>\r\n",
      "\t\t<content>@Jorge_Ruiz14 yo no tengo tiempo para esas cosas ahora mismo </content>\r\n",
      "\t\t<date>2016-08-31 21:07:30</date>\r\n",
      "\t\t<lang>es</lang>\r\n",
      "\t\t<sentiment>\r\n",
      "\t\t\t<polarity><value>N</value></polarity>\r\n",
      "\t\t</sentiment>\r\n",
      "\t</tweet>\r\n",
      "\t<tweet>\r\n",
      "\t\t<tweetid>771094192508600320</tweetid>\r\n",
      "\t\t<user>_cristtina15_</user>\r\n",
      "\t\t<content>@_MissChaotic_ ves ese brillo? es un coso que hace que se sepan a kk </content>\r\n",
      "\t\t<date>2016-08-31 21:15:56</date>\r\n",
      "\t\t<lang>es</lang>\r\n",
      "\t\t<sentiment>\r\n",
      "\t\t\t<polarity><value>N</value></polarity>\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 50 data/intertass-ES-development-tagged.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that the structure is as follows:\n",
    "\n",
    "```\n",
    "tweets: [\n",
    "    tweet({\n",
    "        'tweetid': '',\n",
    "        'user': '',\n",
    "        'content': '',\n",
    "        'date': '',\n",
    "        'lang': '',\n",
    "        'sentiment': {\n",
    "            'polarity': {\n",
    "                'value': ''\n",
    "            }\n",
    "        }\n",
    "    }),\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "From this, what we only really need is the text, because it's what produces the sentiment polarity, and of course the sentiment polarity.\n",
    "\n",
    "These will be nested under `tweet.content` and `tweet.sentiment.polarity.value`.\n",
    "\n",
    "Now that we now what we need to extract, let's get to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the lxml package for this\n",
    "from lxml import objectify, etree\n",
    "\n",
    "def import_data(path):\n",
    "    # We create an empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "    # We parse the file from the path into an etree\n",
    "    tree = etree.parse(path)\n",
    "    # We extract the content as an array from the tweets and add it to a 'content' column on the dataframe\n",
    "    content = []\n",
    "    polarity = []\n",
    "    for tweet in tree.findall('tweet'):\n",
    "        if tweet.find('sentiment') is not None:\n",
    "            content.append(tweet.find('content').text)\n",
    "            polarity.append(tweet.find('sentiment').find('polarity').find('value').text)\n",
    "        elif tweet.find('sentiments') is not None:\n",
    "            content.append(tweet.find('content').text)\n",
    "            polarity.append(tweet.find('sentiments').find('polarity').find('value').text)\n",
    "        else:\n",
    "            continue\n",
    "    df['content'] = content\n",
    "    df['polarity'] = polarity\n",
    "    # And we return the populated dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's actually try this function out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Me caes muy bien \\n-Tienes que jugar más part...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@myendlesshazza a. que puto mal escribo\\n\\nb. ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@estherct209 jajajaja la tuya y la d mucha gen...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quiero mogollón a @AlbaBenito99 pero sobretodo...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vale he visto la tia bebiendose su regla y me ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content polarity\n",
       "0  -Me caes muy bien \\n-Tienes que jugar más part...     NONE\n",
       "1  @myendlesshazza a. que puto mal escribo\\n\\nb. ...        N\n",
       "2  @estherct209 jajajaja la tuya y la d mucha gen...        N\n",
       "3  Quiero mogollón a @AlbaBenito99 pero sobretodo...        P\n",
       "4  Vale he visto la tia bebiendose su regla y me ...        N"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_train = import_data('data/intertass-ES-train-tagged.xml')\n",
    "\n",
    "es_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to have worked.\n",
    "\n",
    "### Understanding the polarity\n",
    "\n",
    "According to the competition's [description](http://www.sepln.org/workshops/tass/2018/task-1/), the sentiment of the tweets has to be classified within one of four categories:\n",
    "\n",
    "* **P**: This applies to tweets that show a positive sentiment\n",
    "* **N**: This applies to tweets that show a negative sentiment\n",
    "* **NEU**: This applies to tweets that show a neutral sentiment\n",
    "* **NONE**: And this applies to tweets that show no sentiment at all\n",
    "\n",
    "So let's look at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Me caes muy bien \n",
      "-Tienes que jugar más partidas al lol con Russel y conmigo\n",
      "-Por qué tan Otako, deja de ser otako\n",
      "-Haber si me muero\n",
      "TAGGED: \"NONE\"\n",
      "====================================================================================================\n",
      "@myendlesshazza a. que puto mal escribo\n",
      "\n",
      "b. me sigo surrando help \n",
      "\n",
      "3. ha quedado raro el \"cómetelo\" ahí JAJAJAJA\n",
      "TAGGED: \"N\"\n",
      "====================================================================================================\n",
      "@estherct209 jajajaja la tuya y la d mucha gente seguro!! Pero yo no puedo sin mi melena me muero \n",
      "TAGGED: \"N\"\n",
      "====================================================================================================\n",
      "Quiero mogollón a @AlbaBenito99 pero sobretodo por lo rápido que contesta a los wasaps \n",
      "TAGGED: \"P\"\n",
      "====================================================================================================\n",
      "Vale he visto la tia bebiendose su regla y me hs dado muchs grima \n",
      "TAGGED: \"N\"\n",
      "====================================================================================================\n",
      "@Yulian_Poe @guillermoterry1 Ah. mucho más por supuesto! solo que lo incluyo. Me habías entendido mal \n",
      "TAGGED: \"P\"\n",
      "====================================================================================================\n",
      "Se ha terminado #Rio2016 Lamentablemente no arriendo las ganancias al pueblo brasileño por la penuria que les espera \n",
      "Suerte y solidaridad\n",
      "TAGGED: \"N\"\n",
      "====================================================================================================\n",
      "11. siiii fue super gracioso teniamos que habernos sacado una foto \n",
      "TAGGED: \"P\"\n",
      "====================================================================================================\n",
      "@toNi_end seria mejor que dejasen de emitir esa basura ya  hay que evolucionar para bien y eso\n",
      "TAGGED: \"N\"\n",
      "====================================================================================================\n",
      "@jonoro96 te mandaria a comprarte un burro, pero no creo que hayan tiendas abiertas ahora \n",
      "TAGGED: \"N\"\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for (_, x) in es_train[:10].iterrows():\n",
    "    print(x['content'])\n",
    "    print('TAGGED: \"{}\"'.format(x['polarity']))\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       418\n",
       "P       318\n",
       "NONE    139\n",
       "NEU     133\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I believe these ones have actually been tagged manually.\n",
    "# Let's take a look at the distributions\n",
    "\n",
    "es_train['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that most of these tweets are negative, followed by positive ones and then by NONE and neutral ones, which represent about 1/3 of the others.\n",
    "\n",
    "Let's now actually load all of the datasets to create a bigger one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now we'll only use the datasets that use tweet text, and see what kind of results we can get\n",
    "es_dev = import_data('data/intertass-ES-development-tagged.xml')\n",
    "cr_train = import_data('data/intertass-CR-train-tagged.xml')\n",
    "cr_dev = import_data('data/intertass-CR-development-tagged.xml')\n",
    "pe_train = import_data('data/intertass-PE-train-tagged.xml')\n",
    "pe_dev = import_data('data/intertass-PE-development-tagged.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally let's merge them all together\n",
    "\n",
    "train_corpus = pd.concat([es_train, es_dev, cr_train, cr_dev, pe_train, pe_dev], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4114, 2)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that leaves us with a dataset with a little over four thousand classified tweets.\n",
    "\n",
    "It's not much, but let's see what we can achieve with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       1406\n",
       "P       1123\n",
       "NONE    1023\n",
       "NEU      562\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is much more balanced than what we had before.\n",
    "\n",
    "### Parsing the text\n",
    "\n",
    "In order to create a classifier, we'll use a count vectorizer. What this does is that it calculates the absolute frequency of a word in a text, and turns the text into a vector of the words with values representing the frequency of each word.\n",
    "\n",
    "And to create this vectorizer define the stopwords that will be found on the text, and we'll also create a function determining how to tokenize the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll get the spanish stopwords from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "es_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming the words**\n",
    "\n",
    "We'll also stem the words.\n",
    "\n",
    "What this means is that we'll take the 'root' of the words, so, words like 'votar', 'votamos', 'votan', 'votación', could have a common stem 'vota'. For this we'll use the Snowball Stemmer from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we import SnowballStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# And create a stemmer\n",
    "stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The tokenization function**\n",
    "\n",
    "We'll now define the function we'll use to tokenize the words. This function will convert the words to tokens. We'll also use the stemmer here, to stem the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # We create a list to store the final tokens\n",
    "    res = []\n",
    "    # We iterate over the words in the text\n",
    "    for word in text.split(\" \"):\n",
    "        # We'll use our remove_special_characters function to clean the words\n",
    "        processed_word = remove_special_characters(word)\n",
    "        try:\n",
    "            # We try to stem the word, in case an exception is raised\n",
    "            res.append(stemmer.stem(processed_word))\n",
    "        except Exception as e:\n",
    "            # If a word cannot be stemmed, we'll just skip it\n",
    "            continue\n",
    "    # And we return the response object\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we're ready to create our count vectorizer!\n",
    "\n",
    "### Creating the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our vectorizer passing in only our tokenizer function, the list of stopwords and a limit of 10000 features\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize, stop_words=es_stopwords, max_features=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! Now we can use the fit_transform function to see what kind of results this produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = vectorizer.fit_transform(train_corpus['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we convert it to an array so that we can see it\n",
    "fitted.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there it is, the result is an array on which each entry is either a 1 or a 0, representing the presence or absence of a given word. We'd expect each array to have an entry for all of the different words in our corpus\n",
    "\n",
    "This is very useful, because now we can create a model that depending on the words that are present, can calculate the probability that the tweets will either be positive, negative, neutral, or have no sentiment\n",
    "\n",
    "## Creating a model\n",
    "\n",
    "Now we have to actually create a model so that we can tag our tweets.\n",
    "\n",
    "What we're going to do next is try two different types of classifiers and see which one would work best.\n",
    "\n",
    "The first one is going to be a linear support vector classification, and the other one will be a naive bayes classifier.\n",
    "\n",
    "So let's try that out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import LinearSVC from SciKitLearn to create the linear vector classifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we create a classifier. For the initial version we'll just use the default values, except for the \n",
    "# random state, which we'll set to 42\n",
    "model = LinearSVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we just fit the model using the vectors we created as X and the tags they have as y\n",
    "model.fit(fitted, train_corpus['polarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. Now we'll vectorize our tweets' text and predict their tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_as_vectors = vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we now create a svc_polarity column to include the tags predicted by the model\n",
    "df['svc_polarity'] = model.predict(tweets_as_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>svc_polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-25 22:06:02</th>\n",
       "      <td>\"La tal paz\"  Significado : Un grupo de terror...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 19:12:03</th>\n",
       "      <td>Antes de decir cosas estúpidamente, ponga en c...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-29 21:04:39</th>\n",
       "      <td>@petrogustavo en Suba!   La caravana de la vid...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31 03:01:07</th>\n",
       "      <td>Las terribles 10 estrategias de manipulación m...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-07 21:36:43</th>\n",
       "      <td>SORRY pic.twitter.com/a4BAeVdhst</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29 23:46:09</th>\n",
       "      <td>Muchas gracias</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-21 22:45:42</th>\n",
       "      <td>Y me imagino que cómo buen observador ya usted...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-24 14:50:11</th>\n",
       "      <td>Sapo gonorriento bloqueado.</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-29 20:18:23</th>\n",
       "      <td>Esta #RataInmunda @davidbarguil ve amenazada s...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11 23:12:06</th>\n",
       "      <td>Máster, nos han robado todo, es hora de que el...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2018-05-25 22:06:02  \"La tal paz\"  Significado : Un grupo de terror...   \n",
       "2018-02-01 19:12:03  Antes de decir cosas estúpidamente, ponga en c...   \n",
       "2018-04-29 21:04:39  @petrogustavo en Suba!   La caravana de la vid...   \n",
       "2018-03-31 03:01:07  Las terribles 10 estrategias de manipulación m...   \n",
       "2018-04-07 21:36:43                   SORRY pic.twitter.com/a4BAeVdhst   \n",
       "2018-05-29 23:46:09                                     Muchas gracias   \n",
       "2018-03-21 22:45:42  Y me imagino que cómo buen observador ya usted...   \n",
       "2018-02-24 14:50:11                        Sapo gonorriento bloqueado.   \n",
       "2018-04-29 20:18:23  Esta #RataInmunda @davidbarguil ve amenazada s...   \n",
       "2018-05-11 23:12:06  Máster, nos han robado todo, es hora de que el...   \n",
       "\n",
       "                    svc_polarity  \n",
       "date                              \n",
       "2018-05-25 22:06:02         NONE  \n",
       "2018-02-01 19:12:03         NONE  \n",
       "2018-04-29 21:04:39         NONE  \n",
       "2018-03-31 03:01:07            P  \n",
       "2018-04-07 21:36:43         NONE  \n",
       "2018-05-29 23:46:09            N  \n",
       "2018-03-21 22:45:42          NEU  \n",
       "2018-02-24 14:50:11            N  \n",
       "2018-04-29 20:18:23            N  \n",
       "2018-05-11 23:12:06            N  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And let's take a look\n",
    "df.sample(10)[['text', 'svc_polarity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it! Let's take a look a little bit more in detail to see what we can spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colombia necesita formalización laboral y, para que las empresas puedan invertir y generar empleo, requieren un sistema tributario más simple, más sano, que ayude a contratar más personal para la expansión de la clase media. @IvanDuque #ElDebateEconómico #EmprenderConDuque pic.twitter.com/xlTzQsTvMD\n",
      "N\n",
      "Petro es la esperanza de Colombia. Vamos hacer historia!!!\n",
      "N\n",
      "Aquel que va a votar por Petro, solamente porque odia a Uribe y por ende a @IvanDuque, está más desorientado que el que va a votar por Petro con plena convicción.\n",
      "P\n",
      "¡Este sábado tendremos nuestro II Gran Encuentro de Jóvenes Con Petro Bogotá! Necesitamos de tu ayuda y la de todos los sectores para llevar a @petrogustavo a la Presidencia en primera vuelta. Para ello organizaremos una hoja de ruta que nos lleve a la victoria. ¡Te esperamos! pic.twitter.com/pMqXIfgPZg\n",
      "N\n",
      "Viene la transformación que tanto hemos esperado, VAMOS A VOTAR BIEN.Vamos a votar por una Colombia inclusiva e innovadora, porque sí podemos hacer valer la democracia. #MerecemosUnFuturoMejor #Vota26Senado #DuquePresidente @IvanDuque @CeDemocratico pic.twitter.com/OL8VVbXlvm\n",
      "NEU\n",
      "Exacto\n",
      "NONE\n",
      "Como la realidad les está tapando la boca a los incrédulos acerca de la propuesta de Petro de energías limpias, @petrogustavo  un visionario! @GustavoBolivar @PetroTOTAL @JaviGuacaneme @nicolaspetroB @BARYMU @D3mocratahttps://twitter.com/elespectador/status/982342175789731841 …\n",
      "P\n",
      "Apreciado doctor. Esperamos la adición en segunda vuelta con @petrogustavo por una Colombia más equitativa.\n",
      "N\n",
      "Esto se dio el viernes.  Sabían?..  no hay porque dejar de producir el@poco@petroleomque tenemos, de forma@sostenible, mientras avanzamos en la vía renovable.http://www.portafolio.co/economia/infraestructura/geb-gana-proyecto-para-sacar-energia-eolica-de-la-guajira-514338 …\n",
      "P\n",
      "En Barranquilla he reafirmando mi compromiso de construir junto con @petrogustavo un Sistema Nacional de Cuidado que de beneficios de vivienda, y educación a las mujeres cuidadoras del hogar.  #ElAtlánticoEsColombiaHumana #PetroPresidente #PrioridadMujeres pic.twitter.com/kFQHOjtk0N\n",
      "NONE\n",
      "Decentes ustedes ,?????? @GustavoBolivar pic.twitter.com/Tik2dcsocw\n",
      "N\n",
      "Ladra la perrera de la oligarquía colombiana. Sienten pisadas de un pueblo que crece agigantado para cerrarle el paso a la corrupción.\n",
      "N\n",
      "A ver le explico, si gana Petro es porque votó una mayoría, entonces resulta más práctico que se vayan los que son menos.\n",
      "P\n",
      "#Contigoharemoselcambio este 11 de marzo, vota #CentroDemocrático104 en la lista a #CámaraTolima; #CentroDemocrático3 en la de Senado por @PalomaValenciaL, y el #1 en la Consulta Interpartidista por @IvanDuque presidente. pic.twitter.com/4nfHnfMoFw\n",
      "NONE\n",
      "Soy estudiante de Comunicación Social y Periodismo, tengo dieciséis años, no tengo edad para votar, pero apoyo a @petrogustavo. Reconozco que #PetroEsLaEsperanza de un país totalmente sumido en la miseria por la horrible clase dirigente. Quiero un mejor país para crecer. pic.twitter.com/Rhfr8o8mhS\n",
      "P\n",
      "Galapa dice Duque Presidente, Marta Lucía Vice. Terminamos por hoy. Voy pa mi casa! @IvanDuque @mluciaramirez pic.twitter.com/bVKzEnAvsl\n",
      "N\n",
      "“Una era de paz es cuando el campesino puede llevar a su hijo a la Universidad. Una era de paz es cuando el gobernante decide que la plata se gasta más en los bebés, en la educación y el saber que en las bombas, los fusiles y las municiones” @petrogustavo pic.twitter.com/YIducjADTA\n",
      "N\n",
      "Hoy miércoles 28 de febrero estará @petrogustavo en Cali / 4PM - Plaza San Francisco #PetroEnCali Invitamos a todos los caleños a asistir con sus vecinos, familiares y amigos a escuchar las propuestas para construir la Colombia Humana!!! pic.twitter.com/0ixA6EYo4p\n",
      "P\n",
      "Veeee omeee \n",
      "N\n",
      "Estimada @vivibustamantet: No soy petrista, no me me reconozco en ninguna etiqueta; fíjese lo curioso, más de un barra brava de Petro me detesta.  Mi voto por @petrogustavo no es emocional, sé que tiene cosas buenas y otras malas como todos, no lo veo como un profeta.   Saludos https://twitter.com/vivibustamantet/status/997668639875784704 …\n",
      "N\n",
      "#DuqueEsCentroDemocrático Representamos una generación de verdadero cambio. Apóyennos! Cámara CD 103 y en la consulta @IvanDuque pic.twitter.com/rHVOKxCK7X\n",
      "NEU\n",
      "El océano nuevo que tenemos que navegar es el de la equidad social, el Litoral Pacífico y la población negra e indígena de Colombia se convierten en prioridad. Que juventudes no sean convocadas a la guerra y muerte sino al saber, arte y educación: @petrogustavo #ElPaísPrimero\n",
      "N\n",
      "Populismo y demagogia en su máxima expresión. Parece que @petrogustavo no se ha enterado que eso es precisamente lo que los jóvenes no quieren. https://twitter.com/petrogustavo/status/991287777173098502 …\n",
      "N\n",
      "En esto  comparto 100% la opinión del doctor @petrogustavo. Ahora, el punto es que ni Fajardo, ni Robledo, ni De la Calle son #Chavistas, pero, en cambio, usted SI es un representante digno del #Chavismo en  https://twitter.com/petrogustavo/status/1002161217677484032 …\n",
      "NEU\n",
      "Seamos honestos, si el voto en blanco tuviera validez alguna yo estaría ahí, de primera haciéndole campaña. Pero como no, nos toca escoger, y claramente prefiero a quien puedo controlar, por eso mi voto es por @petrogustavo.\n",
      "N\n",
      "Ahora, en este momento #PetroEnCartagena, vea en minutos en Vivo por la página de Facebook de @petrogustavo la transmisión. Que se tengan los corruptos. https://www.facebook.com/GustavoPetroUrrego/ … pic.twitter.com/s7uNog1hJ3\n",
      "NONE\n",
      "@IvanDuque  propone el día sin IVA para reactivar el comercio formal https://goo.gl/paJ8mo  #Elecciones2018 #BCNoticias\n",
      "NONE\n",
      "Hablas de este secretario?  https://amp.elespectador.com/noticias/bogota/secretario-de-salud-de-bogota-en-la-mira-de-la-personeria-articulo-705207#click=https://t.co/7Y76tRglcc …\n",
      "N\n",
      "Que coincidencia, que cuando @German_Vargas  hace público que solo él y @petrogustavo  pasarán a segunda vuelta, igual se descubren potenciales atentados contra @IvanDuque .\n",
      "P\n",
      "Ya coronamos my nigga @petrogustavo\n",
      "NONE\n",
      "Las personas que contamos con más de 50 años de edad y conocimientos de historia colombiana y Latinoamericana, sabemos certeramente que el programa de gobierno de @petrogustavo es el que ha propuesto desde Gaitán, hasta Galán y los grandes pensadores liberales social demócratas\n",
      "NONE\n",
      "Los que no somos jurados podemos ser testigos electorales, inscribase en https://petro.com.co/ingreso-testigos/ … o conviértase en testigo electoral de su candidato de preferencia, para que las elecciones sean legítima.\n",
      "P\n",
      "Vamos a trabajar duro, más allá del cansancio,  más allá de la adversidad, en unión y respeto,  Así lograremos que @petrogustavo sea el próximo presidente de Colombia,  eso depende también de nosotros,  \"Palabra Que Si\" pic.twitter.com/XHEf7QqWoV\n",
      "P\n",
      "@petrogustavo My President: Que procede? https://www.elespectador.com/noticias/medio-ambiente/lo-que-esta-pasando-en-guaviare-es-ilegal-inmoral-e-irracional-articulo-742210 …\n",
      "N\n",
      "Empate técnico en encuesta presidencial en el Caribe: - @petrogustavo: 19% - @German_Vargas: 20,4% La diferencia es que la alianza de Petro es con la ciudadanía y a Vargas Lleras le mandaron a \"la gata\" a la casa para que le hiciera campañahttp://m.eltiempo.com/elecciones-colombia-2018/presidenciales/intencion-de-voto-en-el-caribe-para-las-elecciones-presidenciales-segun-encuesta-de-datanalisis-176722 …\n",
      "N\n",
      "Guarumo @ELTIEMPO @WRadioColombia pronostica que @IvanDuque obtendrá en la consulta 558.000 votos más que los logrados por @OIZuluaga en la primera vuelta 2014\n",
      "NONE\n",
      "Quietos en primera base que aquí no se ha definido nada!  @German_Vargas @sergio_fajardo @petrogustavo @IvanDuque @DeLaCalleHum @PinzonBueno @ClaudiaLopez @angelamrobledo @ClaraLopezObre @MafeCarrascal @MartinSantosR @DanielSamperO @Germanmesiasg pic.twitter.com/mOWTVMlDvM\n",
      "NONE\n",
      "Lo que asesina es la falta de medicamentos en puestos de salud, gracias a la ley de la muerte de Uribe, ley 100 Los violentos son otros\n",
      "N\n",
      "Los @JovenesConPetro lo dijimos hace unos días. El proyecto que @petrogustavo le está proponiendo a Colombia no es un invento de él. Son teorías confirmadas por grandes economistas como Thomas Piketty y Joseph Stiglitz. El tiempo nos irá dando la razón con una @ColombiaHumana_ pic.twitter.com/EUtYdeJUNH\n",
      "NONE\n",
      "Saludos desde la Bodega Popayán\n",
      "NONE\n",
      "Gracioso por decir lo menos escuchar a .@DeLaCalleHum manifestándose en contra de la Mermelada, hay que ser muy Caradura, Camaleón. .@IvanDuque 1° en la consulta, (Exige el Tarjetón no lo Ofreceran) @AlvaroUribeVel # 1 @FNAraujoR # 4 senado @CeDemocratico #ManoFirmeCorazónGrande pic.twitter.com/7mjQQbcAWT\n",
      "N\n",
      "Vea pues, curiosamente lo que @Registraduria @jcgalindovacha tachan de errores humanos, todos son a favor del candidato Iván Duque, como se puede observar en los pantallazos tomados @petrogustavo @sergio_fajardo @DeLaCalleHum pic.twitter.com/jVBy8g7MZp\n",
      "NONE\n",
      "#TúEliges  Perfil de Iván Duque (@IvanDuque): el candidato más joven que busca llegar a la Presidencia  http://bit.ly/2xbyg5k  #RCNconTuElección pic.twitter.com/BrDgMg1kNj\n",
      "N\n",
      "En Perú el corrupto Presidente PPK renuncia por sus negocios con Odebrecht,  en Colombia @IvanDuque de tour con Odebrecht lo quieren elegir Presidente.\n",
      "NEU\n",
      "Hollman a eso le dicen C V Y\n",
      "N\n",
      "Una voz la apagaron, pero la otra hoy se alza para luchar por el mismo ideal. Gaitán y @petrogustavo ambos alcaldes destituidos y acusados de comunismo. #PetroPresidente pic.twitter.com/h9VvS7YMuG\n",
      "P\n",
      "Colombia vibra Petro Presidente!!!\n",
      "N\n",
      "Eso lo dice usted.\n",
      "N\n",
      "Otra vez con el cuento del URIBISMO que manera su obsesión con URIBE, superelo...campaña basada en chisme,odio,camorra,odio y las propuestas pacuando!!! los problemas y dificultades del pais son mas grandes que eso, sea serio y coherente. #nostienemamaos.\n",
      "NONE\n",
      "Les dejaré esto aquí.... @petrogustavo  o me va a demandar.??? POR UNA VERDAD. @IvanCepedaCast que va hacer,?? Va a llamar a la policía... Si esto es verdad... Ya se les olvidó????  A nosotros NO.... pic.twitter.com/2hR2tn7maQ\n",
      "P\n"
     ]
    }
   ],
   "source": [
    "for (_, x) in df.sample(50).iterrows():\n",
    "    print(x['text'])\n",
    "    print(x['svc_polarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may see, that's pretty bad. Most of the tweets are completely misclassified.\n",
    "\n",
    "Let's now create a NaiveBayes classifier and see if we might spot a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the MultinomialNB classifier, for we have various possible tags\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# And we create a model, again with the default values\n",
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we fit the model\n",
    "nb_model.fit(fitted, train_corpus['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And let's test that out\n",
    "df['nb_polarity'] = nb_model.predict(tweets_as_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nb_polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-17 22:13:08</th>\n",
       "      <td>#LaGranEncuesta  Si las elecciones fueran maña...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30 16:32:34</th>\n",
       "      <td>Ayer estuvimos en la plaza pública de Santa Ro...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05 20:50:35</th>\n",
       "      <td>A quién piensa engañar con esa mentira? Jajaj ...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-19 23:36:30</th>\n",
       "      <td>Ya está el candidato presidencial @IvanDuque e...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-24 00:36:06</th>\n",
       "      <td>#carismatico @sergio_fajardo  y los  #Detestab...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12 23:07:23</th>\n",
       "      <td>Es el momento del pueblo por fin, a temblar co...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12 20:04:38</th>\n",
       "      <td>Gracias Ministro por la atención, esperamos qu...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-20 21:46:03</th>\n",
       "      <td>Los que no somos jurados podemos ser testigos ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02 00:02:39</th>\n",
       "      <td>Si como no... usted tiene que ser del partido ...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-15 00:05:07</th>\n",
       "      <td>#LlegóLaHora de tener un comandante en jefe qu...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2018-05-17 22:13:08  #LaGranEncuesta  Si las elecciones fueran maña...   \n",
       "2018-04-30 16:32:34  Ayer estuvimos en la plaza pública de Santa Ro...   \n",
       "2018-02-05 20:50:35  A quién piensa engañar con esa mentira? Jajaj ...   \n",
       "2018-04-19 23:36:30  Ya está el candidato presidencial @IvanDuque e...   \n",
       "2018-02-24 00:36:06  #carismatico @sergio_fajardo  y los  #Detestab...   \n",
       "2018-02-12 23:07:23  Es el momento del pueblo por fin, a temblar co...   \n",
       "2018-02-12 20:04:38  Gracias Ministro por la atención, esperamos qu...   \n",
       "2018-05-20 21:46:03  Los que no somos jurados podemos ser testigos ...   \n",
       "2018-02-02 00:02:39  Si como no... usted tiene que ser del partido ...   \n",
       "2018-02-15 00:05:07  #LlegóLaHora de tener un comandante en jefe qu...   \n",
       "\n",
       "                    nb_polarity  \n",
       "date                             \n",
       "2018-05-17 22:13:08         NEU  \n",
       "2018-04-30 16:32:34           N  \n",
       "2018-02-05 20:50:35        NONE  \n",
       "2018-04-19 23:36:30         NEU  \n",
       "2018-02-24 00:36:06           P  \n",
       "2018-02-12 23:07:23         NEU  \n",
       "2018-02-12 20:04:38           P  \n",
       "2018-05-20 21:46:03           P  \n",
       "2018-02-02 00:02:39         NEU  \n",
       "2018-02-15 00:05:07        NONE  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And again, let's take a look\n",
    "df.sample(10)[['text', 'nb_polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En conclusión hoy en día se parece más @petrogustavo que ud mismo a su propio padre\n",
      "NONE\n",
      "#JauriaDeLaBodega Gustavo Petro envía a su “turba”de salvajes aagredir a @German_Vargas y @IvanDuque,quién no ha podido ingresar al recinto para el debate Presidencial..@petrogustavo,controle a sus “perros rabiosos”..!\n",
      "NONE\n",
      "\"Ahorrémonos 250.000 millones de pesos. Elijamos a @IvanDuque \": Alvaro Hernan Prada  YO : Ahorrémonos 50 billones anuales que continuarían robándose el uribismo ó Vargas Lleras. Elijamos a @petrogustavohttps://twitter.com/ALVAROHPRADA/status/975427070024089601 …\n",
      "NEU\n",
      "¡Buenos días #Bosa! Nos vemos a las 10 A.M en el Parque Central junto con @petrogustavo. La política decente se construye del lado de la gente.  #BogotáEsLaGente  #Decentes101 pic.twitter.com/LqIH7vZYXc\n",
      "NEU\n",
      "Pura mierda socialista\n",
      "P\n",
      ". @IvanDuque y @mluciaramirez apoyarán a las familias de bajos recursos para que tengan casa propia. Lo que hoy pagan de arriendo, será ahora el pago de la cuota de su vivienda. #ConMartaLucíaDuquePresidente #DebateDefinitivoEnLaW\n",
      "NONE\n",
      "@petrogustavo Pablo Escobar never became president but he paid the M19 for his favors, @hrw @JMVivancoHRW @ONU_es @CIDH, This is the populist who claims to be president with lies and take us to the road of Venezuela, be carful with this guy\n",
      "NEU\n",
      "\"Me comprometo a que las mujeres rurales tengan la titularidad del crédito y de la tierra\" @petrogustavo #LasMujeresPreguntan #BogotáGanaConPetro pic.twitter.com/2G8U5yxUNK\n",
      "NEU\n",
      "¡ATENTOS! En minutos, en entrevista con @CGurisattiNTN24 y @JoseMAcevedo, el candidato @IvanDuque responde al llamado de @German_Vargas para formar una coalición http://www.noticiasrcn.com pic.twitter.com/DHuuGxfClW\n",
      "NONE\n",
      "Si este fuera un país serio, @IvanDuque retiraría su candidatura por las mentiras comprobas respecto a su formación académica.\n",
      "NEU\n",
      "Que envidia tan berraca la de los mamertos cual es el pecado de que una persona tenga el dinero suficiente para comprarse una propiedad en EEUU, grabe lo de @petrogustavo que adquiere créditos para comprar una casa de un millón de dólares y no paga las cuotas!\n",
      "NONE\n",
      "A pesar de todas las criticas y los estigmas @petrogustavo demuestra que es el mejor candidato,sin alianzas,sin maquinarias,sin partido,sin padrinos políticos.Con un discurso que le llega a la gente.Y sobre como manejo a Bogotá, Peñalosa cada día demuestra que Petro lo hizo bien\n",
      "P\n",
      "En la voz de Armenia, Quindío, en la divulgación de las propuestas de @IvanDuque Presidente, y @mluciaramirez Vicepresidente pic.twitter.com/GUbo98vW6L\n",
      "P\n",
      "#En5díasDuquePresidente @IvanDuque será el presidente que se la juegue por bajar impuestos y mejorar los salarios de los trabajadores colombianos. pic.twitter.com/fWEQ6nI8u2\n",
      "NEU\n",
      "Un votante nuevo, por cada persona que votó por @IvanDuque . Así podríamos ganar en primera vuelta. pic.twitter.com/OZS5C4zpRX\n",
      "N\n",
      "A esta hora, en el Centro Cívico Colombiano en Elmhurst, New York, los #ColombianosEnElExterior  en  fila para inscribir sus cédulas para las Elecciones Presidenciales. ¡Vote por Colombia, Vote por @IvanDuque ! #DuqueEsElQueEs @CeDemocratico @AlvaroUribeVel @NubiaSMartinez pic.twitter.com/rf64IZVk6m\n",
      "N\n",
      "¿Una visión de modernidad, acompañado de Ordóñez? ¿En serio?\n",
      "NONE\n",
      "Exacto!!\n",
      "NONE\n",
      "\"La debilidad de carácter del Gobierno frente al terrorismo, manifestado en la impunidad concedida a las FARC con una JEP hecha a la medida, es ahora la debilidad en la negociación con un ELN envalentonado que quiere poner en jaque al Estado\": @IvanDuque pic.twitter.com/VoqxPk1Hjr\n",
      "NEU\n",
      "A 8 DÍAS, de cumplirse 70 años del MAGNICIDIO del gran líder social, JORGE ELICER GAITAN. 9 de abril actos conmemorativos en Bogotá. @colombia_hist @petrogustavo @HumberticoM @YolandaRuizRCN @roures1 @IVAPESI @rcnradio @jorlinraveles @pedrosalazar420 pic.twitter.com/GnRqKfvDq7\n",
      "NEU\n",
      "Reunión de @IvanDuque y @AlvaroUribeVel con líderes de Somos Región Colombia pic.twitter.com/AUX9hobVpO\n",
      "N\n",
      "Con @IvanDuque miles de familias mejorarán su vivienda, mejorarán su calidad de vida. https://twitter.com/IvanDuque/status/975134231184793601 …\n",
      "NONE\n",
      "Perfecto.\n",
      "P\n",
      "Querida @ClaudiaLopez: en lo del metro de Bogotá @petrogustavo tiene la razón. @JuanManSantos lo torpedeó para influir en las elecciones de 2015, el cálculo le falló y no pudo darle el cheque a @RafaelPardo, por eso el reyezuelo @EnriquePenalosa nos dejó sin metro.https://twitter.com/ClaudiaLopez/status/993858950012514305 …\n",
      "NEU\n",
      "Este lunes 23 de abril 10:30 a.m. la oportunidad es para que los niños puedan participar y preguntar ¿#PresidenteQuéHaríasTú? ¿Contamos con ustedes @sergio_fajardo, @German_Vargas, @DeLaCalleHum, @IvanDuque? El compromiso es con los niños de #Colombia. @UNICEFColombia pic.twitter.com/dpRtG3OFgM\n",
      "NONE\n",
      "\"La erradicación de cultivos ilícitos tiene que ser obligatorio\" @IvanDuque #AgendaEnTacones\n",
      "P\n",
      "Nada que hacer..Centro Democratico le propina paliza al terrorismo,encarnado en @petrogustavo,las Farc,ELN y la Bacrim Casa de Nariño..Buen viento y buena mar,dr. Ivan Duque..! pic.twitter.com/ft0uxWLzQl\n",
      "NONE\n",
      "Sembrando MAIS por una Colombia Humana @petrogustavo @marthaperalta11 @Luis_Evelis @FelicianoValen @GustavoBolivar @AbelDavidJara @PizarroMariaJo @CesarPachonAgro @DavidRacero @ONIC_Colombia @luiskankui @ArrietaJuvenal @HOLLMANMORRIS @LenAmazonas @progresistascol @NaranjaCc pic.twitter.com/3NBjs04EzP\n",
      "NEU\n",
      "Cerca de 9.000.000 De Votos Obtendra @IvanDuque , Se puede Derrotar, hay que multiplicar por 2 los Votos q Obtuvo @petrogustavo , q esta llegando a Muchos abstencionistas, Uno guarda la esperanza q quienes Votaron por Fajardo y De La Calle Saben El Peligro De Un Régimen Uribista.\n",
      "NEU\n",
      "La despedida de @IvanDuque y @mluciaramirez en la Universidad Autónoma de Bucaramanga. Le hubiera ido mejor a Iván en el #DebatePacifico. En las encuestas triplica a todos en aprobación. O eso dicen. 11/04/18. pic.twitter.com/y4aZIds54Q\n",
      "N\n",
      "O sea... no va por los 4 años, va directo a convocar Constituyente para reelección indefinida, porque no solo serían otros 4 añitos, mínimo quiere 10!!!\n",
      "NONE\n",
      "#PetroEnGirón #PetroElFenómenoPolítico sin precedentes en la modernidad, renace la esperanza con la #ColombiaHumana de @petrogustavo #PetroPresidente pic.twitter.com/7cPnGxIruo\n",
      "NEU\n",
      "#AlAire @IvanDuque: Tenemos un compromiso por la defensa de la ancestralidad, estamos dispuestos a hacer valer lo que ha sido nuestra frontera y no permitiremos el despojo de nuestro territorio. pic.twitter.com/KBGFNU0SSA\n",
      "NEU\n",
      "Me preocupa mucho la idea de eliminar la @CConstitucional el @consejodeestado y la @CorteSupremaJ - Una fusión de todas las cortes como la que propone @IvanDuque podría poner en riesgo el precedente constitucional y crear gran inseguridad jurídica https://twitter.com/danielruge/status/977345615192444928 …\n",
      "P\n",
      "¿ @petrogustavo cree Álvaro Uribe es igual que Nicolás Maduro?  https://goo.gl/HW9KKj pic.twitter.com/P7zWt6imxj\n",
      "P\n",
      "Mmmm la venganza la saco usted en su discurso @petrogustavo . Gracias a Dios NO GANÓ, yo no quería un presidente gobernando con odio en cada palabra que lanza. Ni su estilo repugnante: la sátira\n",
      "NEU\n",
      "Contraloría halló responsable a @petrogustavo por pérdida de $279 millones de dólares en negocio de la EEB http://caracol.com.co/radio/2017/06/17/judicial/1497721637_043388.html … vía @caracolradio\n",
      "NEU\n",
      "Hoy es el último día de una hermosa campaña de @IvanDuque y @mluciaramirez sin agresiones, con propuestas, mañana será un día trascendental para los Colombianos, ponemos en tus manos, Dios mío, el resultado!\n",
      "NONE\n",
      "Que bonito acusar a Duque sin tener ninguna prueba. En cambio Petro, sus manos manchadas de la sangre de las víctimas del M19, del cual fue miembro y eso lo hace complice de sus crímenes sobre los cuales el nunca a manifestado arrepentimiento sino orgullo.\n",
      "NONE\n",
      "Hay que estar alertas! En marcha propaganda engañosa contra Petro. No te dejes confundir. Tiembla la corrupción!!  Está en pleno desarrollo un ataque digital masivo contra @petrogustavo. JJ Rendón activó una sarta de infamias (15) compiladas en videos. https://twitter.com/mariolopez1959/status/999776183968501764 …\n",
      "P\n",
      "Que saluditos de las Madres de Soacha, que 'mil gracias por proteger' a sus hijos:  https://www.kienyke.com/historias/pese-su-disculpa-madres-de-soacha-demandaran-alvaro-uribe …\n",
      "P\n",
      "La importancia del aguacate  para la economía de nuestro país . https://www.google.com.co/amp/www.dinero.com/amp/aguacate-exportacion-y-mercado-en-colombia/243434 … Esto lo tiene que leer @IvanDuque porque el prefiere el petróleo. @ContraGodarria @HELIODOPTERO pic.twitter.com/rbCxKicwl3\n",
      "NEU\n",
      "@AlvaroUribeVel Grave!\n",
      "N\n",
      "No hay derecho que .@petrogustavo siga haciendo todo lo que se le da la gana, no respeta las leyes ni a nada. Colombia no merece esto pic.twitter.com/dw0iNPrhiM\n",
      "NONE\n",
      "Y la mamá de la @CGurisattiNTN24 se fue a escuchar lo que decía @petrogustavo en la plaza y se quedó(?) pic.twitter.com/jC88wHw1Hg\n",
      "NONE\n",
      "Por qué a Vargas no le pregunta el país por el estruendoso fracaso del túnel de la línea que inauguró Uribe; por las vías virtuales 4g que inauguró y que están paralizadas. Hacer casas, con la plata nuestra, para hacer política, lo hace un idiota\n",
      "NEU\n",
      "Querido @petrogustavo, cómo para cuándo tu declaración de renta? no nos hagas quedar mal que se la estamos pidiendo a Uribe hace siglos y ahora a sus hijos. Tupe pues.\n",
      "NEU\n",
      "El candidato @petrogustavo firma su compromiso con la Niñez colombiana.  El único candidato que se presentó al Encuentro #NiñezYA pic.twitter.com/s3ZtVRUu32\n",
      "NONE\n",
      "@petrogustavo en el #DebateCaribe a @IvanDuque: \"¿Usted abriría la #JEP a TODOS los actores del conflicto, para que haya verdad y se haga justicia?\". #PetroTuPapá. @IvanDuque se desvió hablando de odio y venganza, porque él y su titiritero creen que JEP es sólo para FARC.\n",
      "NEU\n",
      "Las “patadas de ahogado” de Santos a 4 meses de irse del Gobierno, como el presidente más desprestigiado de la historia: exige a sus contratistas-columnistas que escriban mentiras a su favor e inventen calumnias contra @AlvaroUribeVel e @IvanDuque\n",
      "NEU\n"
     ]
    }
   ],
   "source": [
    "for (_, x) in df.sample(50).iterrows():\n",
    "    print(x['text'])\n",
    "    print(x['nb_polarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, at first sight, this seems like they might be classified slightly better. But still, the result is less than ideal.\n",
    "\n",
    "\n",
    "# Improving the results\n",
    "\n",
    "Training data is crucial when training models (as obvious as that sounds), because the more data we have, the better we can generalize to new data (unless the model is overfitted).\n",
    "\n",
    "So, let's start off by loading more data from the TASS corpuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general-test-tagged-3l.xml\r\n",
      "general-train-tagged.xml\r\n",
      "intertass-CR-development-tagged.xml\r\n",
      "intertass-CR-test.xml\r\n",
      "intertass-CR-train-tagged.xml\r\n",
      "intertass-ES-development-tagged.xml\r\n",
      "intertass-ES-test.xml\r\n",
      "intertass-ES-train-tagged.xml\r\n",
      "intertass-PE-development-tagged.xml\r\n",
      "intertass-PE-test.xml\r\n",
      "intertass-PE-train-tagged.xml\r\n",
      "politics-test-tagged.xml\r\n",
      "socialtv-test-tagged.xml\r\n",
      "socialtv-train-tagged.xml\r\n",
      "stompol-test-tagged.xml\r\n",
      "stompol-train-tagged.xml\r\n"
     ]
    }
   ],
   "source": [
    "! ls data/ | grep xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's loadd some other of the datasets we didn't previously include.\n",
    "\n",
    "general_test = import_data('data/general-test-tagged-3l.xml')\n",
    "general_train = import_data('data/general-train-tagged.xml')\n",
    "politics_test = import_data('data/politics-test-tagged.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpuses = pd.concat([general_test, general_train, politics_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70517, 2)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpuses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're talking!\n",
    "\n",
    "Let's look at the tag distribution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P       24104\n",
       "NONE    23121\n",
       "N       17877\n",
       "NEU      2916\n",
       "P+       1652\n",
       "N+        847\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpuses['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These datasets included new tags N+ and P+, which indicate very negative and very positive sentiments.\n",
    "\n",
    "We'll replace those for N and P, so that we only have 4 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpuses['polarity'] = new_corpuses['polarity'].str.replace('P\\+', 'P')\n",
    "new_corpuses['polarity'] = new_corpuses['polarity'].str.replace('N\\+', 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P       25756\n",
       "NONE    23121\n",
       "N       18724\n",
       "NEU      2916\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpuses['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. Now we have the same set of tags from before. Let's now join these new corpus with our old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_corpus = pd.concat([train_corpus, new_corpuses], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74631, 2)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_corpus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there it is. We now have ~75k classified texts we can use for training.\n",
    "\n",
    "So let's try our models again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use our old vectorizer to fit transform our new data\n",
    "fitted = vectorizer.fit_transform(final_corpus['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And again, we fit the model using the vectors we created as X and the tags they have as y\n",
    "model.fit(fitted, final_corpus['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we do the same with the Naive Bayes model\n",
    "nb_model.fit(fitted, final_corpus['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['svc_polarity_more_data'] = model.predict(tweets_as_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>svc_polarity_more_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-27 13:44:57</th>\n",
       "      <td>¿Por qué @petrogustavo  se mantiene arriba en ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04 20:31:14</th>\n",
       "      <td>La fumigación y erradicación de 250.000 hectár...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 23:35:45</th>\n",
       "      <td>Hola @IvanDuque, ¿podríamos hacer entonces un ...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11 22:59:01</th>\n",
       "      <td>Colombianas y colombianos en Berlín queremos e...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-28 18:26:16</th>\n",
       "      <td>¿Cómo puede un tipo tan inteligente como @petr...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-12 14:19:45</th>\n",
       "      <td>Ni @IvanDuque ni @mluciaramirez me disgustan. ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-15 16:01:38</th>\n",
       "      <td>Las mafias paramilitares y corruptas del uribi...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-13 23:58:46</th>\n",
       "      <td>Cuando @petrogustavo era ENEMIGO de la paz. Ca...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03 20:20:51</th>\n",
       "      <td>Logros de la Bogotá Humana  @petrogustavo Pres...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-24 23:10:54</th>\n",
       "      <td>¿Está permitido poner comparendos por microper...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2018-02-27 13:44:57  ¿Por qué @petrogustavo  se mantiene arriba en ...   \n",
       "2018-04-04 20:31:14  La fumigación y erradicación de 250.000 hectár...   \n",
       "2018-06-07 23:35:45  Hola @IvanDuque, ¿podríamos hacer entonces un ...   \n",
       "2018-06-11 22:59:01  Colombianas y colombianos en Berlín queremos e...   \n",
       "2018-02-28 18:26:16  ¿Cómo puede un tipo tan inteligente como @petr...   \n",
       "2018-03-12 14:19:45  Ni @IvanDuque ni @mluciaramirez me disgustan. ...   \n",
       "2018-04-15 16:01:38  Las mafias paramilitares y corruptas del uribi...   \n",
       "2018-06-13 23:58:46  Cuando @petrogustavo era ENEMIGO de la paz. Ca...   \n",
       "2018-04-03 20:20:51  Logros de la Bogotá Humana  @petrogustavo Pres...   \n",
       "2018-05-24 23:10:54  ¿Está permitido poner comparendos por microper...   \n",
       "\n",
       "                    svc_polarity_more_data  \n",
       "date                                        \n",
       "2018-02-27 13:44:57                      P  \n",
       "2018-04-04 20:31:14                      P  \n",
       "2018-06-07 23:35:45                   NONE  \n",
       "2018-06-11 22:59:01                   NONE  \n",
       "2018-02-28 18:26:16                      N  \n",
       "2018-03-12 14:19:45                      N  \n",
       "2018-04-15 16:01:38                      N  \n",
       "2018-06-13 23:58:46                      P  \n",
       "2018-04-03 20:20:51                      P  \n",
       "2018-05-24 23:10:54                      N  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And again, let's take a look\n",
    "df.sample(10)[['text', 'svc_polarity_more_data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mientras los amigos de los corruptos ya están haciendo maletas para irse del país por si gana @petrogustavo, en todo el mundo hay miles de colombianas que están haciendo maletas para volver si gana la Colombia Humana. pic.twitter.com/9YPiFHz7kC\n",
      "N\n",
      "Oficializada candidatura presidencial de Humberto de la Calle y Clara López #TuVotoDecide @ClaraLopezObre @DeLaCalleHum @petrogustavo @carlosecaicedo http://www.otravoz.co/se-oficializa-formula-presidencial-de-humberto-de-la-calle-y-clara-lopez/ … pic.twitter.com/qtR0m1b61N\n",
      "NONE\n",
      "La elección presidencial para #Boyacá es trascendental por la deuda histórica que tiene el gobierno con la tierra de la libertad (Bicentenario). Es el momento de integrar los medios con la academia para programar un debate en nuestro departamento. @IvanDuque @petrogustavo pic.twitter.com/V6RvANMo0F\n",
      "P\n",
      "Los programas ejecutivos que @IvanDuque cursó en Harvard no confieren título o diploma, solamente una certificación de asistencia. (Adjunto correo de Harvard) pic.twitter.com/qTikq7THyw\n",
      "NONE\n",
      "TU ERES MI LIONEL MESSI @petrogustavo\n",
      "P\n",
      "Me preocupa mucho la idea de eliminar la @CConstitucional el @consejodeestado y la @CorteSupremaJ - Una fusión de todas las cortes como la que propone @IvanDuque podría poner en riesgo el precedente constitucional y crear gran inseguridad jurídica https://twitter.com/danielruge/status/977345615192444928 …\n",
      "NONE\n",
      "La del video es @mafecarrascal  me bloqueo por recordarle el video .. es una de las principales matoneadoras de Petro\n",
      "N\n",
      "Q horror...\n",
      "NONE\n",
      "Gracias por el apoyo a las integrantes del Comité de familias con Duque. @IvanDuque y @mluciaramirez defenderán la familia como núcleo de la sociedad para recuperar el rumbo del país. pic.twitter.com/0dcuHfNZzF\n",
      "P\n",
      "Así se ve el cambio: cientos de miles de colombianas y colombianos decentes y trabajadores llenamos plazas en todo el país acompañando al líder de ideas progresistas @petrogustavo. Hoy Santander de Quilichao ¡Que se tengan los corruptos, llegó la @ColombiaHumana_! pic.twitter.com/K0Imwttr93\n",
      "P\n",
      "Las mismas palabras de @petrogustavo https://twitter.com/nicolasmaduro/status/981290606617088000 …\n",
      "P\n",
      "#AEstaHora nos reunimos con Docentes y jóvenes de Santa Marta para apoyar a @petrogustavo en el camino a la presidencia. #FuerzaConPetro\n",
      "NONE\n",
      "Encuesta de Invamer y yanhas, reflejan una realidad que por años Gobierno quiso ocultar y medios desconocieron, @IvanDuque y @mluciaramirez llegaran a la Presidencia porque la inmensa mayoria de Colombianos pensamos igual que ellos pic.twitter.com/O7QtuGnjeg\n",
      "NEU\n",
      "Gracias a @CeDemocratico por incluirnos a todos los candidatos al @SenadoGovCo para impulsar la campaña de @IvanDuque. Estamos muy honrados por ser parte de un partido que nos tiene en cuenta y nos respalda en todo momento. Lo vamos a dar todo por Colombia! pic.twitter.com/3sAGY55lfp\n",
      "N\n",
      "Así son todos los fantasmas que a menazan @petrogustavo y sus seguidores una partida de pendejos pic.twitter.com/K4qn8JsdNy\n",
      "P\n",
      "La arremetida en redes contra @IvanDuque por parte de quien va de segundo en las encuestas, se hace más violenta cuando le ayuda el pequeño ejército de quien va de cuarto. Están desesperados.\n",
      "P\n",
      "Dijo todo lo contrario. A uds. ya no les queda sino mentir. Le resumo lo que dijo Petro, porque veo que ud. no entendió: pensión de vejez en el RAIS para ingresos altos, pensión dentro del sistema de reparto simple para cotizaciones inferiores a 4 salarios mínimos.\n",
      "NEU\n",
      "La libertad de expresión se vulnera cuando se entrega A DEDO un CANAL PÚBLICO a los ENMERMELADOS del presidente de turno. ¡ESO JAMÁS LO HIZO URIBE!! No sea CÍNICO y BELLACO. RESPETE la inteligencia de los colombianos. Su camarada Maduro: él sí acabo con la libertad de expresión.\n",
      "NONE\n",
      "Venceremos!\n",
      "NONE\n",
      "Y si @petrogustavo no pasa a segunda vuelta,quién pagará las deudas de él y del parásito @nicolaspetroB ?. pic.twitter.com/uoksZuBYOt\n",
      "NONE\n",
      "Dios lo guarde Sr. Francisco, la verdad ante todo y por sobre todo desprecio o simpatía!!\n",
      "N\n",
      "Grande, grande .@AlvaroUribeVel # 1 Senado @CeDemocratico Presidente por Siempre, su huella en mi generación absolutamente indeleble, imborrable, @IvanDuque 1° en La Gran Consulta por Colombia,#EldeUribe #DuqueEsElQueEs Recomiendo @FNAraujoR # 4 Senado CD #ManoFirmeCorazonGrande pic.twitter.com/c3x1sFmT6W\n",
      "NONE\n",
      "Sr. @EnriquePenalosa, no nos venga ahora con el cuento de que el problema de las basuras es de exclusiva responsabilidad del exalcalde @petrogustavo. ¿Acaso no ha sido su mala gestión y sus intereses particulares los que han llevado a Bogotá a decir #LaBasuraDePeñalosa? ¡Respete!\n",
      "N\n",
      "En que son rumores, pruebas,pruebas!!!!!\n",
      "NONE\n",
      "Las empresas también se suman para ganar en primera vuelta con @IvanDuque y @mluciaramirez. Hoy creamos un nuevo comité de voluntarios en Bogotá. #ElFuturoEsDeTodos @CeDemocratico pic.twitter.com/mEwPpIm0q8\n",
      "NONE\n",
      "Mucha atención, acá te comparto los pasas a tener en cuenta para crear un Comité de Voluntarios y lograr que @IvanDuque sea nuestro presidente. #DuquePresidente pic.twitter.com/N4RnAhoonL\n",
      "NONE\n",
      "Lo que está pasando en la @Registraduria es muy grave y creo que lo debemos centrar en cualquiera de los candidatos. Urge tomar medidas para blindar las elecciones de la trampa. Y en eso los periodistas tienen un papel clave. Saludos\n",
      "NONE\n",
      "simplify, if you use mode of transport to gauge wealth statues, you have a long way to go.\n",
      "N\n",
      "Petro lleva a Colombia en su alma en su pluma y su programa, por eso Colombia lo aclama #PetroEnamoraAColombia \n",
      "NEU\n",
      "El partido más importante de mañana será el de Colombia. Y espero que @petrogustavo sea el gol del cambio. Vamos #ColombiaHumana\n",
      "P\n",
      "https://youtu.be/jAkpSj84G7A  video real.\n",
      "NONE\n",
      "Noooo todo menos youtubers\n",
      "P\n",
      "El chiste colombiano   Columna de Carolina Sanin sobre la biografía publicada en la página de @IvanDuque . ||   https://www.vice.com/es_co/article/bjpdk8/el-chiste-colombiano …\n",
      "P\n",
      "Quien vote por @petrogustavo el próximo domingo es comunista, es terrorista, es ignorante o está trabado con sacol y bazuco. Y lo más grave es que no ha visto la película que están presentando allí en Venezuela:  1997 ex-presidente de Venezuela pic.twitter.com/66tUutt2Lv\n",
      "N\n",
      "A la lacra asesina se le olvida q tiene un testigo presencial vivito y coleando, le suena el lugarteniente de su jefe Pablo Escobar??!!\n",
      "P\n",
      "Asesinan testigos, venden miedo, reciclan muerte, gobiernan en cuerpo ajeno. El ciclo de la política tradicional es una película de la mafia: los de siempre con la misma corrupción. Este país necesita de la esperanza indignada que están sembrando @petrogustavo y @angelamrobledo\n",
      "N\n",
      "Vamos a ganar con @IvanDuque pic.twitter.com/VrgdTAIyHj\n",
      "NONE\n",
      "Mis propuestas como candidata a la Cámara por Bogotá. #110 Lista #DECENTES.  @petrogustavo @GloriaFlorezSI @jerojasrodrigue @JovenesConPetro @LtadelaDecencia @charry_manager @HOLLMANMORRIS @sergio_serrano_ @anaidlegna @CesarLopezmusic @SonjoUrpi @nicolaspetroB @PublimetroCol pic.twitter.com/WTYtZuapxl\n",
      "P\n",
      "Bogotá sigue sumando, creamos nuevo comité de voluntarios con @IvanDuque y @mluciaramirez en la localidad de Usaquén. #DuqueEnPrimeraVuelta @CeDemocratico pic.twitter.com/WJsrafEl5w\n",
      "N\n",
      "Excelente Analogía. Para recuperar la esperanza en nuestro país votaremos masivamente por @IvanDuque   No les quepa la menor duda, el triunfo será arrasador y en primera vuelta  https://twitter.com/the__bosch/status/986715069110251520 …\n",
      "P\n",
      "El gobierno de @IvanDuque será el que vuelva a unir al país. Todos queremos la paz, una paz justa con las víctimas y sin impunidad.  @IvanDuque @CeDemocratico #EverthConElQueEs #DuquePresidentehttps://twitter.com/IvanDuque/status/976926965293899781 …\n",
      "N\n",
      "A pesar del clima, jóvenes amantes del fútbol e hinchas de diversos equipos se reúnen a discutir la propuesta presidencial de @petrogustavo y para articular acciones de campaña en la calle. Somos @JovenesConPetro pic.twitter.com/urquNOgxji\n",
      "NEU\n",
      "Nuestros #Diálogos La Fuerza de La Esperanza conquistan los corazones de los ciudadanos; hablando entendemos la importancia de un cambio en Colombia. @petrogustavo es el cambio que el país necesita. #FuerzaConPetro #petropresidente pic.twitter.com/7wHV3yzdah\n",
      "NEU\n",
      "Voté por @German_Vargas convencido que era el más preparado y el mejor ejecutor. Hasta hoy pensaba votar por Duque pero varias cosas no me han gustado los últimos días, en cambio Petro lo ha hecho muy bien. Esto termina de convencerme NO QUIERO UN PRESIDENTE MIEDOSO e inexperto!\n",
      "NONE\n",
      "NOOOO son \n",
      "NONE\n",
      "#FelizDomingo Si la segunda vuelta fuera netre @petrogustavo y @IvanDuque usted voatría por: VOTE Y DIFUNDA!!!!\n",
      "N\n",
      "#Video Cientos de seguidores de @petrogustavo se concentran a las afueras del hotel en Cúcuta para manifestar su apoyo al candidato → http://bit.ly/2tdsFtm \n",
      "P\n",
      "Quienes ayer solo éramos simples \"simpatizantes\" nos duele mas lo que sucede a CD que a quienes vienen militando oficialmente hace tiempo en el Uribismo en Córdoba. Gracias a @JOSEOBDULIO por su valentía y solidaridad. Sigo adelante @AlvaroUribeVel @IvanDuque @CeDemocratico\n",
      "NONE\n",
      "Con @petrogustavo aceleramos en el camino del cambio responsable. Con @IvanDuque nos devolvemos por el corto camino de cambio que habíamos logrado recorrer.\n",
      "P\n",
      "Pase link...\n",
      "NONE\n"
     ]
    }
   ],
   "source": [
    "for (_, x) in df.sample(50).iterrows():\n",
    "    print(x['text'])\n",
    "    print(x['svc_polarity_more_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well this is still very bad. Let's look at these tweets in particular:\n",
    "\n",
    "| Text | polarity |\n",
    "|:----:|:--------:|\n",
    "| Gracias a @CeDemocratico por incluirnos a todos los candidatos al @SenadoGovCo para impulsar la campaña de @IvanDuque. Estamos muy honrados por ser parte de un partido que nos tiene en cuenta y nos respalda en todo momento. Lo vamos a dar todo por Colombia! pic.twitter.com/3sAGY55lfp | N |\n",
    "| Así son todos los fantasmas que a menazan @petrogustavo y sus seguidores una partida de pendejos pic.twitter.com/K4qn8JsdNy | P |\n",
    "| La arremetida en redes contra @IvanDuque por parte de quien va de segundo en las encuestas, se hace más violenta cuando le ayuda el pequeño ejército de quien va de cuarto. Están desesperados. | P |\n",
    "\n",
    "\n",
    "They were all given the actual opposite of the tag. This is very bad.\n",
    "\n",
    "Let's see how the Naive Bayes classifier does with the updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_polarity_more_data'] = nb_model.predict(tweets_as_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nb_polarity_more_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-16 18:05:12</th>\n",
       "      <td>El apoyo a @IvanDuque por parte del sector tex...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06 18:13:06</th>\n",
       "      <td>Gracias Brother!!!</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09 10:52:03</th>\n",
       "      <td>A @AlvaroUribeVel le molesta que las personas ...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-06 21:25:09</th>\n",
       "      <td>Justo por eso las “”</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-24 00:56:10</th>\n",
       "      <td>Yo con @IvanDuque</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09 22:47:33</th>\n",
       "      <td>Hoy Petro en Pregunta Yamid / 10PM / Noticias ...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-14 22:15:00</th>\n",
       "      <td>Jose cuenta con que estoy dedicada a tender pu...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-21 14:55:09</th>\n",
       "      <td>Tan imposible como... pic.twitter.com/ercWX3vhXl</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-27 06:51:59</th>\n",
       "      <td>Colombianos, ¿Dejaremos que se repita la histo...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-23 02:37:36</th>\n",
       "      <td>#EXCLUSIVOCMI | ‘@petrogustavo, @sergio_fajard...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2018-04-16 18:05:12  El apoyo a @IvanDuque por parte del sector tex...   \n",
       "2018-04-06 18:13:06                                 Gracias Brother!!!   \n",
       "2018-04-09 10:52:03  A @AlvaroUribeVel le molesta que las personas ...   \n",
       "2018-05-06 21:25:09                               Justo por eso las “”   \n",
       "2018-02-24 00:56:10                                  Yo con @IvanDuque   \n",
       "2018-04-09 22:47:33  Hoy Petro en Pregunta Yamid / 10PM / Noticias ...   \n",
       "2018-03-14 22:15:00  Jose cuenta con que estoy dedicada a tender pu...   \n",
       "2018-03-21 14:55:09   Tan imposible como... pic.twitter.com/ercWX3vhXl   \n",
       "2018-02-27 06:51:59  Colombianos, ¿Dejaremos que se repita la histo...   \n",
       "2018-02-23 02:37:36  #EXCLUSIVOCMI | ‘@petrogustavo, @sergio_fajard...   \n",
       "\n",
       "                    nb_polarity_more_data  \n",
       "date                                       \n",
       "2018-04-16 18:05:12                  NONE  \n",
       "2018-04-06 18:13:06                  NONE  \n",
       "2018-04-09 10:52:03                   NEU  \n",
       "2018-05-06 21:25:09                     P  \n",
       "2018-02-24 00:56:10                     P  \n",
       "2018-04-09 22:47:33                   NEU  \n",
       "2018-03-14 22:15:00                  NONE  \n",
       "2018-03-21 14:55:09                     N  \n",
       "2018-02-27 06:51:59                   NEU  \n",
       "2018-02-23 02:37:36                   NEU  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And again, let's take a look\n",
    "df.sample(10)[['text', 'nb_polarity_more_data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#AngelaRobledoLaVice seamos sinceros, la izquierda juega con cara y sello, Fajardo y Petro son de la misma línea, aquí el camino diferente es @IvanDuque\n",
      "NONE\n",
      "!! CARTAGENA LISTA para recibir a #DuquePresidente2018 !!  #ConDuqueGanamosTodos @AlvaroUribeVel @IvanDuque @FNAraujoR @javierotero10 pic.twitter.com/EJktSJcm9x\n",
      "P\n",
      "Le dicen caudillo, incendiario, extremista, revanchista, peligroso, pavoroso y no se cuantas vainas más a @petrogustavo ¿Y salen a pedir respeto? ¡COJAN OFICIO! Sí, se lo digo a ustedes la tibia #CoaliciónColombia.  Pdt: #NoSoyPetrista #LosAtiendoDeAUno y que tengan #FelizMartes\n",
      "P\n",
      "Y aun así los medios #FakeNews y encuestadores mermelados mamertos pro izquierda terrorista informan que @sergio_fajardo y @petrogustavo representantes de @FARC_EPueblo van arriba en las encuestas?  Pues no!, la encuesta hoy la muestra Armenia! pic.twitter.com/ON7ur6iMYj\n",
      "P\n",
      "Exactamente @petrogustavo es a la #PoliticaColombiana lo que #GustavoBolivar a la literatura.\n",
      "P\n",
      "Tras fallecimiento de Hugo Chávez, @petrogustavo en entrevista con @elespectador afirmó que el chavismo disminuyó la pobreza en Venezuela. Hoy se vive un éxodo de más de medio millón de venezolanos huyendo de la pobreza y miseria causadas por el régimen.https://www.elespectador.com/noticias/bogota/petro-recuerda-nostalgia-sus-caminatas-chavez-7a-articulo-409099 …\n",
      "P\n",
      "Si las Farc siguieron en el narcotráfico hay que denunciarlos, comprobarlo y extraditarlos: @IvanDuque http://eltelegrafo.co/si-las-farc-siguieron-en-el-narcotrafico-hay-que-denunciarlos-comprobarlo-y-extraditarlos-ivanduque/ …\n",
      "NONE\n",
      "Felicitaciones @petrogustavo más de 4.847.251 han votado por una #ColombiaHumana desde hoy #UnidosGanaPetro y #GanaColombia pic.twitter.com/9cJrvSlXHH\n",
      "P\n",
      "De nuevo esa niña haciendo el oso? Hahahahahahha al menos que se dé cuenta que en ese año no podían usarse mas de 140 caracteres. Pero mas mulas aún, los que creen y dan RT dichosos...\n",
      "N\n",
      "Cubano acusado de pertenecer a ISIS dice que planeaba atentar contra @petrogustavo y @TimoFARC http://ow.ly/Cnnh30jOTZO pic.twitter.com/GPzfFM3Eoc\n",
      "P\n",
      "Presiento que la mayoría de colombianos que recibirán el tamal de @IvanDuque  y @German_Vargas  votarán por @petrogustavo, no se lo presiento :'V\n",
      "NEU\n",
      "Junto a @mluciaramirez participamos en el gran evento de Bogotá, organizado por la concejal @GloriaDiazM  Este 27 de mayo votaremos por @IvanDuque a la presidencia. pic.twitter.com/9IjDiEpQgL\n",
      "NONE\n",
      "\"Les estoy solicitando a @DeLaCalleHum y a @sergio_fajardo que se unan a mi campaña\": @petrogustavo #EleccionesColombia #CityEnLasElecciones\n",
      "NONE\n",
      "Es un honor saber que @IvanDuque cuenta a su lado con una gran mujer cómo lo es @mluciaramirez ejemplo para muchas de nosotros que sabemos que llegó la era de la mujer a Colombia!  #MujeresConDuqueYMartaLucía #IvanDuquePresidente #EnPrimeraVuelta pic.twitter.com/UklPPbSN91\n",
      "P\n",
      "Nuestro equipo de voluntarios continúa llevando el  mensaje de @IvanDuque y @mluciaramirez Seguiremos trabando hasta llegar al último voto.  #DuquePresidente #MartaLuciaVicepresidente pic.twitter.com/chUS3qoQdf\n",
      "NONE\n",
      "El NarcoTerrorista @petrogustavo es tan irresponsable que debe 14 millones de la administración de su casa, y compra zapatos Ferragamo...definitivamente un derrochador como este no puede manejar la economía de nuestra Nación.  http://www.pulzo.com/nacion/deuda-gustavo-petro-con-administracion-conjunto-donde-vive-PP466579 …\n",
      "N\n",
      "¿No les parece curioso que mientras @petrogustavo denuncia su preocupación y la irregularidad que hay tras el manejo de los E-14 los candidatos de la otra consulta guarden silencio?\n",
      "P\n",
      "Contundente victoria de @IvanDuque que marcó además una gran diferencia en votos con @petrogustavo. Reflexión: siguen los encuestadores intentando manipular a los electores. No olvidar para lo que viene: las trampas y fraudes de @JuanManSantos en las votaciones de 2014 y de 2016. pic.twitter.com/DKxhGGkNFn\n",
      "P\n",
      "#ATENCIÓN | ‘Vehículo de @petrogustavo atacado en Cúcuta, no fue impactado con arma de fuego’: Fiscalía http://bit.ly/2FfZE5Y pic.twitter.com/WhQ7JUoeQr\n",
      "N\n",
      "Vigilemos las elecciones para evitar fraudes. @IvanDuque invita a todos los colombianos para que sean voluntarios como testigos electorales el 27 de mayo. Nos podemos inscribir en http://eselquees.com/testigos pic.twitter.com/hHk5A6N5n1\n",
      "N\n",
      "Todos los seguidores de @petrogustavo por favor apoyar #SiSiColombiaSiSiHumana pic.twitter.com/3k6L9pTxuJ\n",
      "P\n",
      "Lo que propone @petrogustavo con referencia al manejo de la tierra en Colombia, es algo que debió hacer el @PartidoLiberal hace décadas. Pero ese partido lo infiltraron los corruptos y los godos como @MoralesViviane y @SOFIAGAVIRIAC.\n",
      "N\n",
      "Retweeted Carlos Caicedo (@carlosecaicedo):  #ConvergenciaPorElCambio #ElPaísPrimero @petrogustavo @sergio_fajardo @DeLaCalleHum pic.twitter.com/3PnaG9boU7 https://twitter.com/carlosecaicedo/status/977368527672958977/photo/1?utm_source=fb&utm_medium=fb&utm_campaign=tacticaperusac&utm_content=977683130248257536 …\n",
      "N\n",
      "Dos asesinatos de líderes en el Pacífico demuestran que la seguridad será uno de los retos más grandes de @petrogustavo o @IvanDuque. Paradójicamente no ha sido un tema de campaña.http://lasillavacia.com/silla-pacifico/la-crecida-de-la-violencia-en-el-pacifico-de-la-que-no-se-habla-en-campana-66414 …\n",
      "NONE\n",
      "Fiscal a @petrogustavo: \"hemos establecido que no hubo armas de fuego en lo acontecido en Cúcuta\" http://bit.ly/2FsWhVk pic.twitter.com/KlbLKEKTI0\n",
      "N\n",
      "Voten por la lista Decentes  Pida el tarjeton de Petro y marqueselo\n",
      "NONE\n",
      "Ya mire su perfil y me ratifico, le lavaron el cerebro, usted es un fanático... busque ayuda.\n",
      "NONE\n",
      "\"Voy a ser el Presidente que saque adelante el Metro de Bogotá\": @IvanDuque\n",
      "NONE\n",
      "Check how @ASCOA’s tracks the performance of presidential candidates in Colombia across major polls. @IvanDuque and @PetroGustavo have grown in the last three months, but are still far from the 50% of votes needed for winning in the first round #LatAm #ColombiaElige #Colombia2018https://twitter.com/ASCOAMedia/status/988831847978332160 …\n",
      "P\n",
      "Aquí una corta intervención de Jaime Bateman, para quienes han escuchado su nombre en los discursos de @petrogustavo. Esto era lo que proponía, y adivinen... también lo mataron. #PetroPresidente  Justicia social. No más los mismos con las mismas. pic.twitter.com/NyZDRD1Hgm\n",
      "P\n",
      "#CierreDeCampaña | “En vez de ser un pelietas como yo, el doctor @IvanDuque es un gran pedagogo”: Uribe en el cierre de campaña en El Tunal https://www.semana.com/elecciones-presidenciales-2018/noticias/cierres-de-campana-de-petro-duque-fajardo-vargas-y-de-la-calle-567917 … pic.twitter.com/o2fXf3SLz4\n",
      "N\n",
      "@petrogustavo CON SUS PALABRAS PAUSADAS QUE DEJAN ENTREVER SU CINISMO Y DESCARO,SOLO PUEDE ENGAÑAR A LOS INCAUTOS QUE CREEN ENCONTRAR EN USTED UN COLCHÓN PARA CONSEGUIRLO TODO SIN TRABAJAR;A ESOS LES DIGO:”DESPIERTEN, PORQUE DESPUÉS TENDRÁN QUE BUSCAR SU COMIDA EN LOS BASUREROS”! https://twitter.com/wradiocolombia/status/960565538463408129 …\n",
      "N\n",
      ".@petrogustavo dice que elecciones en Venezuela no son un resultado democrático http://bit.ly/2KLWjKj  #VocesySonidos pic.twitter.com/609bRlMAJV\n",
      "N\n",
      "El discurso de nuestro candidato @IvanDuque , deja claro que no vamos a recibir mermelados corruptos, menos los 2 de la u que algunos medios han insinuado. Somos la esperanza de Colombia. @CeDemocratico\n",
      "NONE\n",
      "\"Seguridad no es guerra, justicia no es guerra, legalidad no es guerra, lo que nosotros necesitamos en el país es ese feliz matrimonio de seguridad y justicia\"  Hoy @IvanDuque a las 6 pm y 11pm en @LaNocheNTN24 a través de @ntn24 y a las 11:55 pm en @CanalRCN #DuqueEnRCNTV\n",
      "P\n",
      "Ahora son las basuras que casi le cuestan la Alcaldía a @petrogustavo. Podría idearse un sistema para recoger las basuras en bicicletas, utilizar los buses viejos de @TransMilenio o permitir que las motos lleven parrillas acondicionadas para transportar desechos  #BasurasBogota\n",
      "P\n",
      "#Política | @petrogustavo propone ampliar competencias de la JEP a los civiles  ---> https://bit.ly/2HOYLOe pic.twitter.com/ixUxt12AG8\n",
      "N\n",
      "El gran ganador de esta campaña ha sido @IvanDuque  Joven, capacidad y visión de Estado y se ganó el corazón del electorado en una campaña honesta y limpia #DuqueGanador  Falta poco...\n",
      "P\n",
      "#MEDELLÍN El Equipo del Pueblo, está con el candidato del pueblo @petrogustavo #PetroPresidente  Nos vemos ahora en Carabobo, para acompañar al candidato de lxs futbolerxs; el hombre que acabará con la desigualdad y la corrupción ! #AntioquiaEsPetro #MedellinQuiereAPetro pic.twitter.com/mfn3rB4tLP\n",
      "P\n",
      "Critics also say he has been hesitant to distance himself from Hugo Chávez - the late Venezuelan president whom he once supported and who is now blamed for that country’s current woes – and the million Venezuelans who have fled to Colombia.\n",
      "NONE\n",
      "Lástima que @petrogustavo haya  cambiado tanto después de la consulta. Aquí un tuit que le recuperé cuando era buena onda :c pic.twitter.com/x5OtDQ4nLU\n",
      "P\n",
      "No Es presidente y ya se parece a maduro es lo que el diga, fastidia ese señor\n",
      "NONE\n",
      "Seguidores no son votos y viceversa. @petrogustavo es el más popular en Twitter, seguido por @sergio_fajardo pic.twitter.com/D1RIiQa9co\n",
      "P\n",
      "Apoyé la fórmula @German_Vargas @PinzonBueno convencido de que eran la mejor opción por su experiencia y su programa de gobierno. Ahora, ante la realidad, política y sin vacilación alguna, votaré por @IvanDuque en segunda vuelta. La alternativa es impensable.\n",
      "N\n",
      "¿Están preocupados por @petrogustavo? Recuerden que, si @DeLaCalleHum se hubiese metido en esa consulta, Petro no sería el seguro ganador. El caballero estadista negociador toma malas decisiones.\n",
      "N\n",
      "Levanten la mano  los fajardistas e incluso seguidores de De La Calle que votarían por @petrogustavo ...!   Además, se imaginaron que terminarían en la izquierda extrema? ... no era mejor el centro-centro ?   #EleccionesColombia\n",
      "P\n",
      "Talking about why #Colombia's stock market @BVCColombiah has so many problems and how to fix them, it's a shame @IvanDuque didn't use the 'c' word: #corruption, especially with the now-defunct #InterBolsa. https://www.bloomberg.com/news/articles/2018-05-03/meteoric-rise-lifts-d-c-commuter-to-cusp-of-colombia-presidency … #CORRUPCION #ColombiaCorrupta #corrupcionsistemica\n",
      "N\n",
      "Manosear...?Momento...! pic.twitter.com/kAQcuC0WHi\n",
      "NONE\n",
      "#56Razones compatriotas en Miami listas para votar por el 56 al senado y por @IvanDuque pic.twitter.com/oC8ZVg2Sq9\n",
      "NONE\n",
      "Está nota la escribe @juanjose2811 un héroe de la patria, víctima del terrorismo. Hoy deportista de alta competencia y ejemplo de superación y alegría para todos. Comprensible su dolor. Inadmisible que utilicen abusivamente su imagen en tono de burla seguidores de @petrogustavo. https://twitter.com/juanjose2811/status/987772766064693248 …\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "for (_, x) in df.sample(50).iterrows():\n",
    "    print(x['text'])\n",
    "    print(x['svc_polarity_more_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These, again seem not that great. The error is still very high. So, the next step we can take is tuning the model parameters to get more accurate classifiers.\n",
    "\n",
    "## Tuning the model parameters\n",
    "\n",
    "So, in order to better tune the model parameters, we're going to use GridSearchCV.\n",
    "\n",
    "This way, we can pass different configuration values to test with and in the end, it will return the parameters that produce the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we continue, let's first actually create a Pipeline. This pipeline will indicate that the flow of our data will be like:\n",
    "\n",
    "`data -> vectorizer.fit_transform -> model.train|fit`\n",
    "\n",
    "This way, we can find the best parameters both for the tokenizer and for the classifiers at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://www.pybonacci.org/2015/11/24/como-hacer-analisis-de-sentimiento-en-espanol-2/\n",
    "# and https://github.com/manugarri/tweets_map/blob/master/4.%20Sentiment%20Analysis.ipynb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# We define the pipeline for the SVC\n",
    "svc_pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# And a separate one for the NB classifier\n",
    "nb_pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', nb_model)\n",
    "])\n",
    "\n",
    "# And now we can define parameters both for the vectorizer and the classifier using their keys\n",
    "svc_pipeline_grid_params = {\n",
    "    'vectorizer__min_df': (10, 20, 50),\n",
    "    'vectorizer__max_features': (10000, 20000),\n",
    "    'vectorizer__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'classifier__C': (0.2, 0.5, 0.7),\n",
    "    'classifier__loss': ('hinge', 'squared_hinge'),\n",
    "    'classifier__max_iter': (500, 1000)\n",
    "}\n",
    "\n",
    "# And different parameters for the NB classifier\n",
    "nb_pipeline_grid_params = {\n",
    "    'vectorizer__min_df': (0, 10, 20, 50),\n",
    "    'vectorizer__max_features': (10000, 20000),\n",
    "    'vectorizer__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'classifier__alpha': (0, .5, 1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=10000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['de... max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'vectorizer__min_df': (10, 20, 50), 'vectorizer__max_features': (10000, 20000), 'vectorizer__ngram_range': ((1, 1), (1, 2), (1, 3)), 'classifier__C': (0.2, 0.5, 0.7), 'classifier__loss': ('hinge', 'squared_hinge'), 'classifier__max_iter': (500, 1000)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now we search for the best params fo the SVC\n",
    "svc_grid_search = GridSearchCV(svc_pipeline, svc_pipeline_grid_params, n_jobs=3, scoring='accuracy')\n",
    "\n",
    "# And we fit the data using the grid search\n",
    "svc_grid_search.fit(final_corpus['content'], final_corpus['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/home/santiago/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=10000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['de...e18>, vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'vectorizer__min_df': (0, 10, 20, 50), 'vectorizer__max_features': (10000, 20000), 'vectorizer__ngram_range': ((1, 1), (1, 2), (1, 3)), 'classifier__alpha': (0, 0.5, 1)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we do the same for the NB classifier\n",
    "nb_grid_search = GridSearchCV(nb_pipeline, nb_pipeline_grid_params, n_jobs=3, scoring='accuracy')\n",
    "\n",
    "# And again, we fit the data using the grid search\n",
    "nb_grid_search.fit(final_corpus['content'], final_corpus['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.2,\n",
       " 'classifier__loss': 'hinge',\n",
       " 'classifier__max_iter': 500,\n",
       " 'vectorizer__max_features': 10000,\n",
       " 'vectorizer__min_df': 10,\n",
       " 'vectorizer__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the model with the best params\n",
    "model = LinearSVC(\n",
    "    C=.2,\n",
    "    loss='hinge',\n",
    "    max_iter=500\n",
    ")\n",
    "\n",
    "# And we create the vectorizer with the best params\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 3)\n",
    ")\n",
    "\n",
    "fitted = vectorizer.fit_transform(final_corpus.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6701898561766234"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    fitted[0:len(final_corpus)],\n",
    "    y=final_corpus['polarity'],\n",
    "    scoring='accuracy',\n",
    "    cv=5\n",
    "    )\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(fitted, final_corpus['polarity'])\n",
    "\n",
    "fitted_tweets = vectorizer.fit_transform(df['text'])\n",
    "df['optimized_svc_polarity'] = model.predict(fitted_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>optimized_svc_polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-07 23:59:42</th>\n",
       "      <td>ESTE ASESINO, VIOLADOR, EJECUTOR DE LA MASACRE...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06 22:11:02</th>\n",
       "      <td>EXACTAMENTE EL MISMO RAZONAMIENTO de su camara...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-09 22:30:50</th>\n",
       "      <td>Hoy @IvanDuque en @VozPopuli pic.twitter.com/U...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12 23:11:59</th>\n",
       "      <td>\"Se vive, se siente, Petro PRESIDENTE\" es la c...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-08 21:25:38</th>\n",
       "      <td>Los jóvenes de #ElPaísPrimero no lo dejamos so...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30 23:25:08</th>\n",
       "      <td>Ante tanta calumnia hacia @IvanDuque propongo ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-15 21:28:09</th>\n",
       "      <td>#DuqueEsCorrupción en el César nos reporta que...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-11 23:15:59</th>\n",
       "      <td>Así ganemos la consulta interpartidista con @p...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01 21:53:33</th>\n",
       "      <td>#APetroLoFinanciaElPueblo con donaciones en ef...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18 18:44:15</th>\n",
       "      <td>Seguidores de @petrogustavo, a piedra y en bat...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-20 23:17:08</th>\n",
       "      <td>\"Con Everth Bustamante #26  tenemos un camino ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04 15:21:31</th>\n",
       "      <td>Señoras y señores Petro es portada de Rolling ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30 22:35:13</th>\n",
       "      <td>Profe Mockus lo necesitamos! que no le tiemble...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-17 21:57:59</th>\n",
       "      <td>Con Galán de fondo seguimos con el perifoneo y...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-03 23:33:38</th>\n",
       "      <td>Se merece una #IndiaCatalina2018   Será que @V...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-27 23:54:37</th>\n",
       "      <td>El apoyo de @MovimientoMIRA clave para una vic...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-21 16:31:48</th>\n",
       "      <td>\"La inversión realizada por el FVS, dignifica ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-28 22:41:59</th>\n",
       "      <td>Si es presidente @petrogustavo al año los urib...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 23:01:44</th>\n",
       "      <td>Miré la cuenta de @petrogustavo en promedio me...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31 22:39:14</th>\n",
       "      <td>Su comentario sí fue racista. Su odio hacia lo...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2018-04-07 23:59:42  ESTE ASESINO, VIOLADOR, EJECUTOR DE LA MASACRE...   \n",
       "2018-04-06 22:11:02  EXACTAMENTE EL MISMO RAZONAMIENTO de su camara...   \n",
       "2018-03-09 22:30:50  Hoy @IvanDuque en @VozPopuli pic.twitter.com/U...   \n",
       "2018-02-12 23:11:59  \"Se vive, se siente, Petro PRESIDENTE\" es la c...   \n",
       "2018-04-08 21:25:38  Los jóvenes de #ElPaísPrimero no lo dejamos so...   \n",
       "2018-05-30 23:25:08  Ante tanta calumnia hacia @IvanDuque propongo ...   \n",
       "2018-06-15 21:28:09  #DuqueEsCorrupción en el César nos reporta que...   \n",
       "2018-03-11 23:15:59  Así ganemos la consulta interpartidista con @p...   \n",
       "2018-05-01 21:53:33  #APetroLoFinanciaElPueblo con donaciones en ef...   \n",
       "2018-04-18 18:44:15  Seguidores de @petrogustavo, a piedra y en bat...   \n",
       "2018-02-20 23:17:08  \"Con Everth Bustamante #26  tenemos un camino ...   \n",
       "2018-02-04 15:21:31  Señoras y señores Petro es portada de Rolling ...   \n",
       "2018-05-30 22:35:13  Profe Mockus lo necesitamos! que no le tiemble...   \n",
       "2018-03-17 21:57:59  Con Galán de fondo seguimos con el perifoneo y...   \n",
       "2018-03-03 23:33:38  Se merece una #IndiaCatalina2018   Será que @V...   \n",
       "2018-05-27 23:54:37  El apoyo de @MovimientoMIRA clave para una vic...   \n",
       "2018-04-21 16:31:48  \"La inversión realizada por el FVS, dignifica ...   \n",
       "2018-04-28 22:41:59  Si es presidente @petrogustavo al año los urib...   \n",
       "2018-06-07 23:01:44  Miré la cuenta de @petrogustavo en promedio me...   \n",
       "2018-03-31 22:39:14  Su comentario sí fue racista. Su odio hacia lo...   \n",
       "\n",
       "                    optimized_svc_polarity  \n",
       "date                                        \n",
       "2018-04-07 23:59:42                      P  \n",
       "2018-04-06 22:11:02                   NONE  \n",
       "2018-03-09 22:30:50                      P  \n",
       "2018-02-12 23:11:59                      P  \n",
       "2018-04-08 21:25:38                   NONE  \n",
       "2018-05-30 23:25:08                      P  \n",
       "2018-06-15 21:28:09                      P  \n",
       "2018-03-11 23:15:59                   NONE  \n",
       "2018-05-01 21:53:33                      P  \n",
       "2018-04-18 18:44:15                      P  \n",
       "2018-02-20 23:17:08                      N  \n",
       "2018-02-04 15:21:31                      P  \n",
       "2018-05-30 22:35:13                   NONE  \n",
       "2018-03-17 21:57:59                      P  \n",
       "2018-03-03 23:33:38                      P  \n",
       "2018-05-27 23:54:37                      P  \n",
       "2018-04-21 16:31:48                      P  \n",
       "2018-04-28 22:41:59                   NONE  \n",
       "2018-06-07 23:01:44                      N  \n",
       "2018-03-31 22:39:14                   NONE  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(20)[['text', 'optimized_svc_polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 1,\n",
       " 'vectorizer__max_features': 20000,\n",
       " 'vectorizer__min_df': 0,\n",
       " 'vectorizer__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the model with the best params\n",
    "model = MultinomialNB(\n",
    "    alpha=1\n",
    ")\n",
    "\n",
    "# And we create the vectorizer with the best params\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=0,\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "\n",
    "fitted = vectorizer.fit_transform(final_corpus.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(fitted, final_corpus['polarity'])\n",
    "\n",
    "fitted_tweets = vectorizer.fit_transform(df['text'])\n",
    "df['optimized_svc_polarity'] = model.predict(fitted_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>optimized_svc_polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-14 20:07:59</th>\n",
       "      <td>#PetroEnPositivoEnLaW Vuelven a atacar los enj...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-15 23:30:15</th>\n",
       "      <td>Trabaje mijo y vera lo fácil q es conseguir</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-19 23:06:22</th>\n",
       "      <td>reviselo aqui: https://visor.digitalizacione14...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05 00:01:59</th>\n",
       "      <td>Jajajaja!!! Ahhh Palomita, nunca decepcionas!!...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-05 20:25:05</th>\n",
       "      <td>Praying 4 that day</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-08 23:23:27</th>\n",
       "      <td>Importante....esto puede significar que @IvanD...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27 16:04:00</th>\n",
       "      <td>.@IvanDuque se viste de canciller: así marcha ...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-25 23:02:24</th>\n",
       "      <td>Esta noche en el debate de @CaracolTV   ¿Quién...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-11 19:41:42</th>\n",
       "      <td>EN VIVO #PulsoporelPoder | 'La distribución d...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-20 23:17:08</th>\n",
       "      <td>\"Con Everth Bustamante #26  tenemos un camino ...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-16 21:47:59</th>\n",
       "      <td>En Monteria apoyando la candidatura de @IvanDu...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27 22:23:53</th>\n",
       "      <td>Desmonte gradual pero efectivo y real de los \"...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-02 16:13:01</th>\n",
       "      <td>A estas alturas, la elección del presidente se...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-17 01:51:18</th>\n",
       "      <td>Para mí lo que vale es el ser bueno y además p...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09 14:47:00</th>\n",
       "      <td>Jóvenes de #ElPaísPrimero queremos hacer un pa...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-14 16:03:57</th>\n",
       "      <td>Comité de Voluntarios, Lorica, Córdoba. Un gob...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15 01:57:09</th>\n",
       "      <td>#ColombiaDecide | Estas son las principales pr...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-15 16:51:27</th>\n",
       "      <td>En cambio me alegra que haya gente que vote co...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-28 23:58:12</th>\n",
       "      <td>@petrogustavo por favor enviar video a whatsapp</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-09 20:19:56</th>\n",
       "      <td>#ATENCIÓN Las consecuencias del odio que promu...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2018-06-14 20:07:59  #PetroEnPositivoEnLaW Vuelven a atacar los enj...   \n",
       "2018-02-15 23:30:15        Trabaje mijo y vera lo fácil q es conseguir   \n",
       "2018-03-19 23:06:22  reviselo aqui: https://visor.digitalizacione14...   \n",
       "2018-02-05 00:01:59  Jajajaja!!! Ahhh Palomita, nunca decepcionas!!...   \n",
       "2018-05-05 20:25:05                                Praying 4 that day    \n",
       "2018-06-08 23:23:27  Importante....esto puede significar que @IvanD...   \n",
       "2018-04-27 16:04:00  .@IvanDuque se viste de canciller: así marcha ...   \n",
       "2018-05-25 23:02:24  Esta noche en el debate de @CaracolTV   ¿Quién...   \n",
       "2018-03-11 19:41:42   EN VIVO #PulsoporelPoder | 'La distribución d...   \n",
       "2018-02-20 23:17:08  \"Con Everth Bustamante #26  tenemos un camino ...   \n",
       "2018-02-16 21:47:59  En Monteria apoyando la candidatura de @IvanDu...   \n",
       "2018-04-27 22:23:53  Desmonte gradual pero efectivo y real de los \"...   \n",
       "2018-05-02 16:13:01  A estas alturas, la elección del presidente se...   \n",
       "2018-03-17 01:51:18  Para mí lo que vale es el ser bueno y además p...   \n",
       "2018-04-09 14:47:00  Jóvenes de #ElPaísPrimero queremos hacer un pa...   \n",
       "2018-04-14 16:03:57  Comité de Voluntarios, Lorica, Córdoba. Un gob...   \n",
       "2018-05-15 01:57:09  #ColombiaDecide | Estas son las principales pr...   \n",
       "2018-03-15 16:51:27  En cambio me alegra que haya gente que vote co...   \n",
       "2018-05-28 23:58:12    @petrogustavo por favor enviar video a whatsapp   \n",
       "2018-06-09 20:19:56  #ATENCIÓN Las consecuencias del odio que promu...   \n",
       "\n",
       "                    optimized_svc_polarity  \n",
       "date                                        \n",
       "2018-06-14 20:07:59                    NEU  \n",
       "2018-02-15 23:30:15                    NEU  \n",
       "2018-03-19 23:06:22                   NONE  \n",
       "2018-02-05 00:01:59                   NONE  \n",
       "2018-05-05 20:25:05                   NONE  \n",
       "2018-06-08 23:23:27                    NEU  \n",
       "2018-04-27 16:04:00                    NEU  \n",
       "2018-05-25 23:02:24                    NEU  \n",
       "2018-03-11 19:41:42                    NEU  \n",
       "2018-02-20 23:17:08                    NEU  \n",
       "2018-02-16 21:47:59                      P  \n",
       "2018-04-27 22:23:53                      P  \n",
       "2018-05-02 16:13:01                    NEU  \n",
       "2018-03-17 01:51:18                    NEU  \n",
       "2018-04-09 14:47:00                    NEU  \n",
       "2018-04-14 16:03:57                    NEU  \n",
       "2018-05-15 01:57:09                    NEU  \n",
       "2018-03-15 16:51:27                    NEU  \n",
       "2018-05-28 23:58:12                   NONE  \n",
       "2018-06-09 20:19:56                    NEU  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(20)[['text', 'optimized_svc_polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
